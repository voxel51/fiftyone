# Dataset Creation Examples

Examples of creating datasets with FiftyOne.

## Working with publicly available datasets

> Factory method: `fiftyone.zoo.load_zoo_dataset()`

The `fiftyone.zoo` package provides a collection of datasets that you can
download and load into FiftyOne with a single command:

```py
import fiftyone.zoo as foz

# List available datasets
print(foz.list_zoo_datasets())

# Load a zoo dataset
# The dataset will be downloaded from the web the first time you access it
dataset = foz.load_zoo_dataset("cifar10")

# Print a few samples from the dataset
print(dataset.sample())
```

Behind the scenes, FiftyOne uses the
[TensorFlow Datasets](https://www.tensorflow.org/datasets) or
[TorchVision Datasets](https://pytorch.org/docs/stable/torchvision/datasets.html)
libraries to wrangle the datasets, depending on which ML library you have
installed. In order to load datasets using TF, you must have the
[tensorflow-datasets](https://pypi.org/project/tensorflow-datasets) package
installed on your machine. In order to load datasets using PyTorch, you must
have the [torch](https://pypi.org/project/torch) and
[torchvision](https://pypi.org/project/torchvision) packages installed.

> Note that the ML backends may expose different datasets

#### Customizing your ML backend

By default, FiftyOne will use whichever ML backend is available. If both are
found, it will use the backend specified by the `tf.config.default_ml_backend`
setting in your FiftyOne config.

You can customize this backend in any of the following ways:

-   directly editing your FiftyOne config at `~/.fiftyone/config.json`

```shell
# Print your current config
fiftyone config --print

# Locate your config
fiftyone constants FIFTYONE_CONFIG_PATH
```

-   setting the `FIFTYONE_DEFAULT_ML_BACKEND` environment variable

```shell
# Example: use the `tensorflow` backend
export FIFTYONE_DEFAULT_ML_BACKEND="tensorflow"
```

-   adding the following commands to your Python code _before_ importing the
    `fiftyone.zoo` package:

```py
# Example: use the `torch` backend
import fiftyone.core.config as foc
foc.set_config_settings(default_ml_backend="torch")
```

## Building your own dataset from scratch

> Factory method: `fiftyone.Dataset.add_samples()`

FiftyOne datasets are composed of `fiftyone.core.sample.Sample`s, and FiftyOne
provides the ability for you to construct your own dataset from scratch by
creating your own samples, if desired.

The following example demonstrates the construction of a dataset with ground
truth labels stored in the `ground_truth` group:

```py
import fiftyone as fo

# Dict mapping int targets to label strings
labels_map = ...

# A list of `(image_path, target)` tuples
samples = ...

# Construct your dataset manually
_samples = []
for image_path, target in samples:
    _sample = fo.Sample.create(image_path, tags={"train"})
    _sample.add_label(
        "ground_truth", fo.ClassificationLabel.create(labels_map[target])
    )
    _samples.append(_sample)

dataset = fo.Dataset("my-dataset")
dataset.add_samples(samples)

# Print a few samples from the dataset
print(dataset.sample())
```

## Working with image classification samples

> Factory method: `fiftyone.Dataset.from_image_classification_samples()`

FiftyOne provides native support for working with image classification samples
whose images are stored on disk and whose corresponding predictions are stored
in-memory.

In the code below, the input `samples` can be any iterable that emits
`(image_path, target)` tuples, where:

-   `image_path` is the path to the image on disk

-   `target` is either a label string, or, if a `labels_map` is provided, a
    class ID that can be mapped to a label string via `labels_map[target]`

For example, `samples` may be a `torch.utils.data.Dataset` or an iterable
generated by `tf.data.Dataset.as_numpy_iterator()`.

If your samples do not fit this schema, you can use the
`fiftyone.Dataset.from_labeled_image_samples()` factory method to provide your
own `fiftyone.utils.data.LabeledImageSampleParser` to parse your samples.

```py
import fiftyone as fo

# Dict mapping int targets to label strings
labels_map = ...

# A list of `(image_path, target)` tuples
samples = ...

dataset = fo.Dataset.from_image_classification_samples(
    samples, labels_map=labels_map
)
```

## Working with image detection samples

> Factory method: `fiftyone.Dataset.from_image_detection_samples()`

FiftyOne provides native support for working with image detection samples whose
images are stored on disk and whose corresponding detections are stored
in-memory.

In the code below, the input `samples` can be any iterable that emits
`(image_path, detections)` tuples, where:

-   `image_path` is the path to the image on disk

-   `detections` is a list of detections in the following format:

```
[
    {
        "label": <label>,
        "bounding_box": [
            <top-left-x>, <top-left-y>, <width>, <height>
        ],
        "confidence": <optional-confidence>,
    },
    ...
]
```

where `label` is either a label string, or, if a `labels_map` is provided, a
class ID that can be mapped to a label string via `labels_map[label]`, and the
bounding box coordinates are relative values in `[0, 1] x [0, 1]`.

For example, `samples` may be a `torch.utils.data.Dataset` or an iterable
generated by `tf.data.Dataset.as_numpy_iterator()`.

If your samples do not fit this schema, you can use the
`fiftyone.Dataset.from_labeled_image_samples()` factory method to provide your
own `fiftyone.utils.data.LabeledImageSampleParser` to parse your samples.

```py
import fiftyone as fo

# Dict mapping int targets to label strings
labels_map = ...

# A list of `(image_path, detections)` tuples
samples = ...

dataset = fo.Dataset.from_image_detection_samples(
    samples, labels_map=labels_map
)
```

## Working with multitask image prediction samples

> Factory method: `fiftyone.Dataset.from_image_labels_samples()`

FiftyOne provides native support for working with multitask image predictions
samples whose images are stored on disk and whose corresponding labels are
stored in-memory.

In the code below, the input `samples` can be any iterable that emits
`(image_path, image_labels)` tuples, where:

-   `image_path` is the path to the image on disk

-   `image_labels` is an `eta.core.image.ImageLabels` instance or a serialized
    dict representation of one

For example, `samples` may be a `torch.utils.data.Dataset` or an iterable
generated by `tf.data.Dataset.as_numpy_iterator()`.

See https://voxel51.com/docs/api/#types-imagelabels for more information on the
`ImageLabels` format.

If your samples do not fit this schema, you can use the
`fiftyone.Dataset.from_labeled_image_samples()` factory method to provide your
own `fiftyone.utils.data.LabeledImageSampleParser` to parse your samples.

```py
import fiftyone as fo

# Dict mapping int targets to label strings
labels_map = ...

# A list of `(image_path, image_labels)` tuples
samples = ...

dataset = fo.Dataset.from_image_labels_samples(samples, labels_map=labels_map)
```

## Working with custom labeled image samples

> Factory method: `fiftyone.Dataset.from_labeled_image_samples()`

FiftyOne provides support for working with custom labeled image datasets whose
label formats differ from the native classification, detection, and multitask
structures described above.

In the code below, the input `samples` can be any iterable that emits
`(image_path, label)` tuples, where:

-   `image_path` is the path to the image on disk

-   `label` is a `fiftyone.core.labels.Label` instance containing the image
    labels(s)

If your samples require preprocessing to convert to the above format, you can
provide a custom `fiftyone.utils.data.LabeledImageSampleParser` instance via
the `sample_parser` argument whose
`fiftyone.utils.data.LabeledImageSampleParser.parse_label()` method will be
used to parse the sample labels in the input iterable.

```py
import fiftyone as fo
from fiftyone.utils.data import LabeledImageSampleParser


class MyLabeledImageSampleParser(LabeledImageSampleParser):
    """Your custom sample parser class."""

    def parse_label(self, sample):
        """Parses the label from the given sample.

        Args:
            sample: the sample

        Returns:
            a :class:`fiftyone.core.labels.Label` instance
        """
        # @todo: parse the sample and return the label in the correct format


# A list of `(image_path, your_custom_labels)` tuples
samples = ...

# The sample parser that will be used to parse
sample_parser = MyLabeledImageSampleParser()

dataset = fo.Dataset.from_labeled_image_samples(
    samples, sample_parser=sample_parser
)
```

## Ingesting labeled image samples stored in-memory

> Factory method: `fiftyone.Dataset.ingest_labeled_image_samples()`

FiftyOne provides support for ingesting labeled image datasets that are stored
as in-memory collections of images and labels.

In the method below, `samples` can be any iterable that emits
`(image_or_path, label)` tuples, where:

-   `image_or_path` is either an image that can be converted to numpy format
    via `np.asarray()` or the path to an image on disk

-   `label` is a `fiftyone.core.labels.Label` instance

If your samples require preprocessing to convert to the above format, you can
provide a custom `fiftyone.utils.data.LabeledImageSampleParser` instance via
the `sample_parser` argument whose
`fiftyone.utils.data.LabeledImageSampleParser.parse()` method will be used to
parse the input samples.

The code below demonstrates using the default
`fiftyone.utils.data.ImageClassificationSampleParser` to ingest an image
classification dataset stored in-memory:

```py
import fiftyone as fo
import fiftyone.utils.data as fod

# Dict mapping int targets to label strings
labels_map = ...

# A list of `(img, target)` tuples
samples = ...

sample_parser = fodu.ImageClassificationSampleParser(labels_map=labels_map)
dataset = fo.Dataset.ingest_labeled_image_samples(
    samples,
    dataset_dir="/tmp/dataset",
    sample_parser=sample_parser,
)
```

## Working with image classification datasets stored on disk

> Factory method: `fiftyone.Dataset.from_image_classification_dataset()`

FiftyOne provides native support for loading image classification datasets that
are stored on disk in the following format:

```
<dataset_dir>/
    data/
        <uuid1>.<ext>
        <uuid2>.<ext>
        ...
    labels.json
```

where `labels.json` is a JSON file in the following format:

```
{
    "labels_map": {
        <targetA>: <labelA>,
        <targetB>: <labelB>,
        ...
    },
    "labels": {
        <uuid1>: <target1>,
        <uuid2>: <target2>,
        ...
    }
}
```

This dataset format is encapsulated by the
`fiftyone.types.ImageClassificationDataset` type in FiftyOne.

You can load an image classification dataset backed by `dataset_dir` via the
following command:

```py
import fiftyone as fo

dataset = fo.Dataset.from_image_classification_dataset(dataset_dir)

# Print a few samples from the dataset
print(dataset.sample())
```

## Working with image detection datasets stored on disk

> Factory method: `fiftyone.Dataset.from_image_detection_dataset()`

FiftyOne provides native support for loading image detection datasets that are
stored on disk in the following format:

```
<dataset_dir>/
    data/
        <uuid1>.<ext>
        <uuid2>.<ext>
        ...
    labels.json
```

where `labels.json` is a JSON file in the following format:

```
{
    "labels_map": {
        <targetA>: <labelA>,
        <targetB>: <labelB>,
        ...
    },
    "labels": {
        <uuid1>: [
            {
                "label": <label>,
                "bounding_box": [
                    <top-left-x>, <top-left-y>, <width>, <height>
                ],
                "confidence": <optional-confidence>,
            },
            ...
        ],
        <uuid2>: [
            ...
        ],
        ...
    }
}
```

and where the bounding box coordinates are expressed as relative values in
`[0, 1] x [0, 1]`.

This dataset format is encapsulated by the
`fiftyone.types.ImageDetectionDataset` type in FiftyOne.

You can load an image detection dataset backed by `dataset_dir` via the
following command:

```py
import fiftyone as fo

dataset = fo.Dataset.from_image_detection_dataset(dataset_dir)

# Print a few samples from the dataset
print(dataset.sample())
```

## Working with multitask image prediction datasets stored on disk

> Factory method: `fiftyone.Dataset.from_image_labels_dataset()`

FiftyOne provides native support for loading multitask image prediction
datasets that are stored on disk in the following format:

```
<dataset_dir>/
    data/
        <uuid1>.<ext>
        <uuid2>.<ext>
        ...
    labels/
        <uuid1>.json
        <uuid2>.json
        ...
    manifest.json
```

where `manifest.json` is a JSON file in the following format:

```
{
    "type": "eta.core.datasets.LabeledImageDataset",
    "description": "",
    "index": [
        {
            "data": "data/<uuid1>.<ext>",
            "labels": "labels/<uuid1>.json"
        },
        ...
    ]
}
```

and where each labels JSON file is stored in `eta.core.image.ImageLabels`
format. See https://voxel51.com/docs/api/#types-imagelabels for more details.

This dataset format is encapsulated by the `fiftyone.types.ImageLabelsDataset`
type in FiftyOne.

You can load a multitask image labels dataset backed by `dataset_dir` via the
following command:

```py
import fiftyone as fo

dataset = fo.Dataset.from_image_labels_dataset(dataset_dir)

# Print a few samples from the dataset
print(dataset.sample())
```

## Copyright

Copyright 2017-2020, Voxel51, Inc.<br> voxel51.com
