{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Smart Sample Selection\n",
    "\n",
    "Random sampling wastes labels on redundant near-duplicates. This step uses **diversity-based selection** to pick high-value samples that cover your data distribution efficiently.\n",
    "\n",
    "We'll use **ZCore (Zero-Shot Coreset Selection)** to score samples based on:\n",
    "- **Coverage**: How much of the embedding space does this sample represent?\n",
    "- **Redundancy**: How many near-duplicates exist?\n",
    "\n",
    "High ZCore score = valuable for labeling. Low score = redundant, skip it.\n",
    "\n",
    "> **Reference:** ZCore is from [Voxel51's research](https://github.com/voxel51/zcore). The implementation below is simplified for understanding. For production use with large datasets, see the official repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import numpy as np\n",
    "\n",
    "dataset = fo.load_dataset(\"annotation_tutorial\")\n",
    "pool = dataset.load_saved_view(\"pool\")\n",
    "\n",
    "print(f\"Pool size: {len(pool)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Embeddings\n",
    "\n",
    "Diversity selection needs embeddings to understand dataset structure. We'll compute them using FiftyOne Brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings (takes a few minutes)\n",
    "fob.compute_visualization(\n",
    "    dataset,\n",
    "    embeddings=\"embeddings\",\n",
    "    brain_key=\"img_viz\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Embeddings computed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZCore: Zero-Shot Coreset Selection\n",
    "\n",
    "ZCore scores each sample by iteratively:\n",
    "1. Sampling random points in embedding space\n",
    "2. Finding the nearest data point (coverage bonus)\n",
    "3. Penalizing nearby neighbors (redundancy penalty)\n",
    "\n",
    "The result: samples covering unique regions score high; redundant samples score low.\n",
    "\n",
    "> **Note:** This is a simplified reference implementation. It works well for datasets up to a few thousand samples. For larger datasets, use the optimized version at [github.com/voxel51/zcore](https://github.com/voxel51/zcore)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcore_score(embeddings, n_sample=10000, sample_dim=2, redund_nn=100, redund_exp=4, seed=42):\n",
    "    \"\"\"\n",
    "    Compute ZCore scores for coverage-based sample selection.\n",
    "    \n",
    "    Reference implementation from https://github.com/voxel51/zcore\n",
    "    For production use with large datasets, use the official package.\n",
    "    \n",
    "    Args:\n",
    "        embeddings: np.array of shape (n_samples, embedding_dim)\n",
    "        n_sample: Number of random samples to draw\n",
    "        sample_dim: Number of dimensions to sample at a time\n",
    "        redund_nn: Number of nearest neighbors for redundancy penalty\n",
    "        redund_exp: Exponent for distance-based redundancy penalty\n",
    "        seed: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        Normalized scores (0-1) where higher = more valuable for labeling\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    n = len(embeddings)\n",
    "    n_dim = embeddings.shape[1]\n",
    "    \n",
    "    # Embedding statistics\n",
    "    emb_min = np.min(embeddings, axis=0)\n",
    "    emb_max = np.max(embeddings, axis=0)\n",
    "    emb_med = np.median(embeddings, axis=0)\n",
    "    \n",
    "    # Initialize scores\n",
    "    scores = np.random.uniform(0, 1, n)\n",
    "    \n",
    "    for i in range(n_sample):\n",
    "        if i % 2000 == 0:\n",
    "            print(f\"  ZCore progress: {i}/{n_sample}\")\n",
    "        \n",
    "        # Random embedding dimensions\n",
    "        dim = np.random.choice(n_dim, min(sample_dim, n_dim), replace=False)\n",
    "        \n",
    "        # Sample point using triangular distribution (biased toward median)\n",
    "        sample = np.random.triangular(emb_min[dim], emb_med[dim], emb_max[dim])\n",
    "        \n",
    "        # Coverage: find nearest sample to random point\n",
    "        embed_dist = np.sum(np.abs(embeddings[:, dim] - sample), axis=1)\n",
    "        idx = np.argmin(embed_dist)\n",
    "        scores[idx] += 1  # Reward coverage\n",
    "        \n",
    "        # Redundancy: penalize nearby neighbors\n",
    "        cover_sample = embeddings[idx, dim]\n",
    "        nn_dist = np.sum(np.abs(embeddings[:, dim] - cover_sample), axis=1)\n",
    "        nn = np.argsort(nn_dist)[1:]  # Exclude self\n",
    "        \n",
    "        if nn_dist[nn[0]] == 0:\n",
    "            # Exact duplicate\n",
    "            scores[nn[0]] -= 1\n",
    "        else:\n",
    "            # Distance-weighted penalty for neighbors\n",
    "            nn = nn[:redund_nn]\n",
    "            dist_penalty = 1 / (nn_dist[nn] ** redund_exp + 1e-8)\n",
    "            dist_penalty /= np.sum(dist_penalty)\n",
    "            scores[nn] -= dist_penalty\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores) + 1e-8)\n",
    "    \n",
    "    return scores.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings for pool samples\n",
    "pool_samples = list(pool)\n",
    "embeddings = np.array([s.embeddings for s in pool_samples if s.embeddings is not None])\n",
    "valid_ids = [s.id for s in pool_samples if s.embeddings is not None]\n",
    "\n",
    "print(f\"Computing ZCore for {len(embeddings)} samples...\")\n",
    "print(f\"Embedding dimension: {embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ZCore scores\n",
    "# n_sample=5000 is fast for tutorials; increase for larger datasets\n",
    "scores = zcore_score(\n",
    "    embeddings,\n",
    "    n_sample=5000,\n",
    "    sample_dim=2,\n",
    "    redund_nn=50,\n",
    "    redund_exp=4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\nZCore scores computed!\")\n",
    "print(f\"Score range: {scores.min():.3f} - {scores.max():.3f}\")\n",
    "print(f\"Mean: {scores.mean():.3f}, Std: {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ZCore scores to samples\n",
    "for sample_id, score in zip(valid_ids, scores):\n",
    "    sample = dataset[sample_id]\n",
    "    sample[\"zcore\"] = float(score)\n",
    "    sample.save()\n",
    "\n",
    "print(f\"Added 'zcore' field to {len(valid_ids)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Your First Batch\n",
    "\n",
    "**How many samples to label?**\n",
    "\n",
    "A good starting point:\n",
    "- **50-200 samples** for initial batch (1-2 hours of labeling)\n",
    "- Size subsequent batches based on your labeling throughput\n",
    "- Typical iteration: half-day to one-day of labeling per batch\n",
    "\n",
    "For this tutorial with ~130 pool samples, we'll select about 30 (roughly 25%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload pool to see new zcore field\n",
    "pool = dataset.load_saved_view(\"pool\")\n",
    "\n",
    "# Select top samples by ZCore score\n",
    "# Adjust batch_size based on your labeling capacity\n",
    "batch_size = min(30, int(0.25 * len(pool)))  # ~30 samples or 25% of pool\n",
    "batch_v0 = pool.sort_by(\"zcore\", reverse=True).limit(batch_size)\n",
    "\n",
    "print(f\"Selected {len(batch_v0)} samples for Batch 0\")\n",
    "print(f\"ZCore range of selected: {min(s.zcore for s in batch_v0):.3f} - {max(s.zcore for s in batch_v0):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag the selection\n",
    "batch_v0.tag_samples(\"batch:v0\")\n",
    "batch_v0.tag_samples(\"to_annotate\")\n",
    "batch_v0.set_values(\"annotation_status\", [\"selected\"] * len(batch_v0))\n",
    "\n",
    "# Save as view\n",
    "dataset.save_view(\"batch_v0\", dataset.match_tags(\"batch:v0\"))\n",
    "\n",
    "print(f\"Tagged and saved view: batch_v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize in the App\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the App:\n",
    "1. Open the **Embeddings** panel to see the 2D projection\n",
    "2. Color by the `zcore` field to see the score distribution\n",
    "3. Filter by `batch:v0` tag to see your selection\n",
    "4. Verify high-ZCore samples are spread across clusters (good coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Diversity Sampling Beats Random\n",
    "\n",
    "| Method | What it does | Result |\n",
    "|--------|-------------|--------|\n",
    "| **Random** | Picks samples uniformly | Over-samples dense regions, misses rare cases |\n",
    "| **ZCore** | Balances coverage vs redundancy | Maximizes diversity, fewer wasted labels |\n",
    "\n",
    "Research shows diversity-based selection can significantly reduce labeling requirements while maintaining model performance. See the [ZCore paper](https://arxiv.org/pdf/2411.15349) for detailed benchmarks on ImageNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You selected a diverse batch using ZCore:\n",
    "- Computed embeddings to map images to vector space\n",
    "- Ran ZCore algorithm to score coverage vs redundancy\n",
    "- Selected top samples by ZCore score\n",
    "- Tagged as `batch:v0` and `to_annotate`\n",
    "\n",
    "**Artifacts:**\n",
    "- `embeddings` field on all samples\n",
    "- `zcore` field with selection scores\n",
    "- `batch_v0` saved view\n",
    "\n",
    "**Next:** Step 4 - Annotation + QA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
