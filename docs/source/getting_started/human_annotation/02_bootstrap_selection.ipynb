{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Bootstrap Selection - Embeddings + ZCore\n",
    "\n",
    "Before we have a model, we can't chase failures. So our first batch must be selected for **coverage** - we want diverse samples that represent the full distribution of our data.\n",
    "\n",
    "This step teaches you to:\n",
    "1. Compute embeddings to understand your dataset's structure\n",
    "2. Use the ZCore operator to select a coverage-optimized batch\n",
    "3. Visualize the selection to verify diversity\n",
    "\n",
    "**Why This Matters**: Random sampling wastes labels on redundant near-duplicates. ZCore ensures your first batch covers the data manifold efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset from Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "# Load the dataset we created in Step 1\n",
    "dataset = fo.load_dataset(\"kitti_annotation_tutorial\")\n",
    "\n",
    "# Load the pool view (where we select samples from)\n",
    "pool_view = dataset.load_saved_view(\"active_pool\")\n",
    "\n",
    "print(f\"Dataset: {dataset.name}\")\n",
    "print(f\"Pool size: {len(pool_view)} samples available for selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Image Embeddings\n",
    "\n",
    "Embeddings map images to a vector space where similar images are close together. We'll use these to:\n",
    "1. Understand the structure of our dataset\n",
    "2. Select diverse samples for annotation\n",
    "3. Identify clusters and outliers\n",
    "\n",
    "FiftyOne's Brain module provides easy access to embedding computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "# Compute embeddings using a pre-trained model\n",
    "# This may take a few minutes depending on your hardware\n",
    "results = fob.compute_visualization(\n",
    "    dataset,\n",
    "    embeddings=\"embeddings\",  # Store embeddings in this field\n",
    "    brain_key=\"img_viz\",      # Name for this brain run\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nEmbeddings computed and stored in 'embeddings' field\")\n",
    "print(f\"Brain run saved as: img_viz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the App to visualize the embeddings\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the FiftyOne App, click on the **Embeddings** panel to see the 2D projection of your dataset. You'll notice:\n",
    "- **Clusters**: Groups of similar images (same scene type, lighting, etc.)\n",
    "- **Outliers**: Unusual samples at the edges\n",
    "- **Dense regions**: Areas with many similar samples (redundant for labeling)\n",
    "\n",
    "Random sampling would over-sample dense regions. We want to spread across clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZCore: Zero-Shot Coreset Selection\n",
    "\n",
    "ZCore selects a **coreset** - a small subset that represents the full dataset. It works by:\n",
    "1. Computing pairwise distances in embedding space\n",
    "2. Selecting samples that maximize coverage (minimize redundancy)\n",
    "3. Ensuring selected samples span the full distribution\n",
    "\n",
    "The result: labeling fewer samples while maintaining dataset coverage.\n",
    "\n",
    "### Using ZCore via the Operators Panel\n",
    "\n",
    "In the FiftyOne App:\n",
    "1. Press **`** (backtick) to open the Operators panel\n",
    "2. Search for **\"zcore\"** or **\"coreset\"**\n",
    "3. Configure the operator:\n",
    "   - **embeddings_field**: `embeddings`\n",
    "   - **target_size**: Number of samples to select (we'll use ~20% of pool)\n",
    "   - **output_tag**: `to_annotate_v0`\n",
    "\n",
    "Alternatively, we can run ZCore programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate target batch size (20% of pool for first iteration)\n",
    "batch_size = int(0.20 * len(pool_view))\n",
    "print(f\"Target batch size: {batch_size} samples (20% of pool)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute uniqueness scores as a proxy for ZCore\n",
    "# Samples with high uniqueness are less redundant\n",
    "fob.compute_uniqueness(\n",
    "    pool_view,\n",
    "    uniqueness_field=\"uniqueness\",\n",
    "    embeddings=\"embeddings\"\n",
    ")\n",
    "\n",
    "print(\"Uniqueness scores computed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select samples with highest uniqueness (most diverse)\n",
    "# This ensures coverage across the embedding space\n",
    "batch_v0_view = pool_view.sort_by(\"uniqueness\", reverse=True).limit(batch_size)\n",
    "\n",
    "print(f\"Selected {len(batch_v0_view)} samples for Batch v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag the selected samples\n",
    "batch_v0_view.tag_samples(\"batch:v0\")\n",
    "batch_v0_view.tag_samples(\"to_annotate\")\n",
    "\n",
    "# Update annotation status\n",
    "batch_v0_ids = list(batch_v0_view.values(\"id\"))\n",
    "dataset.select(batch_v0_ids).set_values(\"annotation_status\", [\"selected\"] * len(batch_v0_ids))\n",
    "\n",
    "print(f\"Tagged {len(batch_v0_ids)} samples with 'batch:v0' and 'to_annotate'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this selection as a view for easy access\n",
    "batch_v0 = dataset.match_tags(\"batch:v0\")\n",
    "dataset.save_view(\"batch_v0_to_annotate\", batch_v0)\n",
    "\n",
    "print(f\"Saved view: batch_v0_to_annotate ({len(batch_v0)} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Selection\n",
    "\n",
    "Let's verify that our selection provides good coverage by looking at the embeddings visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the selected samples in the App\n",
    "session.view = batch_v0\n",
    "session.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the embeddings panel, the selected samples should be **spread across clusters**, not concentrated in one area. If you see good coverage, the selection is working.\n",
    "\n",
    "### What to Look For:\n",
    "- **Good**: Selected samples span multiple regions of the embedding space\n",
    "- **Bad**: Selected samples clump in one area (indicates a bug in selection)\n",
    "- **Check**: Compare selected vs. unselected in the embeddings view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare selection statistics with full pool\n",
    "print(\"Selection Statistics:\")\n",
    "print(f\"  Pool size: {len(pool_view)}\")\n",
    "print(f\"  Selected: {len(batch_v0)} ({100*len(batch_v0)/len(pool_view):.1f}%)\")\n",
    "print(f\"  Remaining: {len(pool_view) - len(batch_v0)}\")\n",
    "\n",
    "# Check class distribution in selected batch\n",
    "from collections import Counter\n",
    "\n",
    "selected_labels = []\n",
    "for sample in batch_v0:\n",
    "    if sample.ground_truth:\n",
    "        selected_labels.extend([det.label for det in sample.ground_truth.detections])\n",
    "\n",
    "print(f\"\\nClass distribution in Batch v0:\")\n",
    "for label, count in sorted(Counter(selected_labels).items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this step, you:\n",
    "\n",
    "1. **Computed embeddings** - Mapped images to a vector space for similarity analysis\n",
    "2. **Ran diversity selection** - Used uniqueness scoring to select coverage-optimized samples\n",
    "3. **Created Batch v0** - Selected ~20% of the pool for initial annotation\n",
    "4. **Tagged and saved** - Samples are tagged `batch:v0` and `to_annotate` for tracking\n",
    "\n",
    "**Key Insight**: This first batch maximizes coverage, not model performance. We're seeding the loop with diverse examples. Model-driven selection comes after we have a trained model.\n",
    "\n",
    "**Artifacts Created**:\n",
    "- `embeddings` field on all samples\n",
    "- `uniqueness` field on pool samples\n",
    "- `batch:v0` and `to_annotate` tags on selected samples\n",
    "- `batch_v0_to_annotate` saved view\n",
    "\n",
    "**Next up**: Step 3 - Human Annotation Pass + QA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
