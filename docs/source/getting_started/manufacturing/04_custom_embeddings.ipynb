{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a029f92a"
   },
   "source": [
    "# Custom Embeddings for Anomaly Detection\n",
    "\n",
    "In this notebook, we will explore how to generate **custom embeddings** for **anomaly detection** using the **Padim model** from Anomalib.\n",
    "Unlike general-purpose embeddings from models like CLIP or ResNet, anomaly detection requires **task-specific embeddings** that can distinguish between normal and abnormal samples.\n",
    "\n",
    "![anomaly_mvtec](https://cdn.voxel51.com/getting_started_manufacturing/notebook4/anomaly_mvtec.webp)\n",
    "\n",
    "\n",
    "## Learning Objectives:\n",
    "- Understand the difference between standard embeddings and anomaly-specific embeddings.\n",
    "- Explore how to compute embeddings using **Padim from Anomalib**.\n",
    "- Integrate these embeddings into a FiftyOne dataset.\n",
    "- Leverage FiftyOne for visualization and analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "196000c7"
   },
   "source": [
    "\n",
    "## Why Use Custom Embeddings for Anomaly Detection?\n",
    "\n",
    "Pre-trained models like **CLIP or ResNet** generate **general-purpose embeddings** that focus on visual similarity. However, detecting **abnormalities** requires learning **subtle deviations** from normal patterns, which these models cannot capture effectively.\n",
    "\n",
    "Instead, we use a dedicated anomaly detection model like **Padim from Anomalib**, which:\n",
    "- Learns representations specific to normal and anomalous samples.\n",
    "- Extracts feature maps from an encoder (e.g., ResNet).\n",
    "- Compares new samples against normal feature distributions.\n",
    "\n",
    "### Further Reading:\n",
    "- [Anomalib Documentation](https://github.com/openvinotoolkit/anomalib)\n",
    "- [Understanding Memory-Based Anomaly Detection](https://arxiv.org/pdf/2011.08785)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13331,
     "status": "ok",
     "timestamp": 1759167386961,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "ao8nBiXRe7lB",
    "outputId": "3073e260-b4f9-4731-c72e-fe8f16cca8a3"
   },
   "outputs": [],
   "source": [
    "!pip install fiftyone huggingface_hub gdown umap-learn torch torchvision scikit-learn python-dotenv anomalib open-clip-torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkIa-yjte5kn"
   },
   "source": [
    "## Load the MVTec Dataset as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3734,
     "status": "ok",
     "timestamp": 1759167423276,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "nSJDVkiUXv90",
    "outputId": "124ca440-8416-4b57-b3c6-b11802aa92ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Get the appropriate device for model inference.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "DEVICE = get_device()\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKL0PUZNOiO4"
   },
   "source": [
    "# Download dataset from source\n",
    "\n",
    "We can download the file from Google Drive using `gdown`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T39P7zikOkfM"
   },
   "source": [
    "Let's get started by importing the FiftyOne library, and the utils we need for a COCO format dataset, depending of the dataset format you should change that option. [Supported Formats](https://docs.voxel51.com/user_guide/dataset_creation/datasets.html#supported-formats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11363,
     "status": "ok",
     "timestamp": 1759167444559,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "jShgcNrce5kn",
    "outputId": "33b5d9e8-31d4-4380-855b-92b2cc0fa88a"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "# Download the coffee dataset from Google Drive\n",
    "\n",
    "url = \"https://drive.google.com/uc?id=1nAuFIyl2kM-TQXduSJ9Fe_ZEIVog4tth\" # original\n",
    "gdown.download(url, output=\"mvtec_ad.zip\", quiet=False)\n",
    "\n",
    "!unzip mvtec_ad.zip\n",
    "\n",
    "import fiftyone as fo # base library and app\n",
    "#import fiftyone.utils.huggingface as fouh # Hugging Face integration\n",
    "\n",
    "# Define the new dataset name\n",
    "dataset_name = \"MVTec_AD_cEmb\"\n",
    "\n",
    "# Check if the dataset exists\n",
    "if dataset_name in fo.list_datasets():\n",
    "    print(f\"Dataset '{dataset_name}' exists. Loading...\")\n",
    "    dataset = fo.load_dataset(dataset_name)\n",
    "else:\n",
    "    print(f\"Dataset '{dataset_name}' does not exist. Creating a new one...\")\n",
    "    # Clone the dataset with a new name and make it persistent\n",
    "    #dataset_ = fouh.load_from_hub(\"Voxel51/mvtec-ad\", persistent=True, overwrite=True)\n",
    "    dataset_ = fo.Dataset.from_dir(\n",
    "        dataset_dir=\"/content/mvtec-ad\",\n",
    "        dataset_type=fo.types.FiftyOneDataset\n",
    "    )\n",
    "    dataset = dataset_.clone(\"MVTec_AD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af37356c"
   },
   "source": [
    "\n",
    "## Extracting Custom Embeddings from Padim (Anomalib)\n",
    "\n",
    "Instead of using a general embedding model, we will:\n",
    "1. **Load a Padim anomaly detection model** using Anomalib.\n",
    "2. **Run inference on a dataset** to extract anomaly embeddings.\n",
    "3. **Store the embeddings in FiftyOne** for further visualization.\n",
    "\n",
    "**Relevant Documentation:**  \n",
    "- [Anomalib Models](https://anomalib.readthedocs.io/en/latest/markdown/guides/reference/models/image/index.html)  \n",
    "- [Remotely-sourced Zoo Models](https://docs.voxel51.com/model_zoo/remote.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "490f64f581684790b7a1e8307d58f68e",
      "7f734f4e568a496f85019f1526b3defa",
      "5eda7ab8d3e74b3182f551f165ea1355",
      "15af93f8efd745fbb9a0af3f14f69b06",
      "256a7852527e43f7b6cd09559e70b323",
      "d1eb541071354357bd1a15aec2cd6f2e",
      "19435e821d624c4691c535a7cbd8f0e1",
      "906dea5e54434f8a993a3a0753a65df5",
      "ada86e09bddc459591dfdacaf4efbfcb",
      "6e2d3d951d044a909053b095711e701a",
      "d9954b4f10b9445d9ae9f22b7e7c044c"
     ]
    },
    "executionInfo": {
     "elapsed": 7432,
     "status": "ok",
     "timestamp": 1759167461033,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "3_jaz8w-e5ko",
    "outputId": "2010d7ce-37dd-4d79-bf52-16698923c980"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490f64f581684790b7a1e8307d58f68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PadimModel(\n",
       "  (feature_extractor): TimmFeatureExtractor(\n",
       "    (feature_extractor): FeatureListNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anomaly_map_generator): AnomalyMapGenerator(\n",
       "    (blur): GaussianBlur2d()\n",
       "  )\n",
       "  (gaussian): MultiVariateGaussian()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from anomalib.models.image.padim.torch_model import PadimModel\n",
    "\n",
    "# Create a PaDiM model\n",
    "model = PadimModel(\n",
    "    backbone=\"resnet18\",           # or \"wide_resnet50_2\", etc.\n",
    "    layers=[\"layer1\", \"layer2\"],   # choose the layers you want\n",
    "    pre_trained=True,\n",
    "    n_features=100                 # optional dimension reduction\n",
    ")\n",
    "model.eval()  # set to eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1759167468670,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "_rJo2v_qe5ko",
    "outputId": "3138eaff-de9f-4d09-c563-d9f3c54c529a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PadimModel(\n",
      "  (feature_extractor): TimmFeatureExtractor(\n",
      "    (feature_extractor): FeatureListNet(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_block): Identity()\n",
      "          (act1): ReLU(inplace=True)\n",
      "          (aa): Identity()\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act2): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (anomaly_map_generator): AnomalyMapGenerator(\n",
      "    (blur): GaussianBlur2d()\n",
      "  )\n",
      "  (gaussian): MultiVariateGaussian()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 818,
     "status": "ok",
     "timestamp": 1759167503450,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "13nP2DCle5ko",
    "outputId": "17ef47cb-1612-453a-e958-1b1231deb841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "from anomalib.models.image.padim.lightning_model import Padim\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# 1) Create the Lightning-based PaDiM\n",
    "padim = Padim(\n",
    "    backbone=\"resnet18\",\n",
    "    layers=[\"layer1\", \"layer2\"],\n",
    "    pre_trained=True\n",
    ")\n",
    "padim.train()  # so forward(...) returns embeddings\n",
    "\n",
    "# 2) Load image\n",
    "transform = T.Compose([T.Resize(224), T.ToTensor()])\n",
    "\n",
    "# Replace this with the path to your image\n",
    "image_path = \"/content/mvtec-ad/data/data_0/000.png\"\n",
    "pil_image = Image.open(image_path).convert(\"RGB\")\n",
    "tensor = transform(pil_image).unsqueeze(0)  # (1, C, H, W)\n",
    "\n",
    "# 3) Pass it through the model in train mode\n",
    "with torch.no_grad():\n",
    "    embeddings = padim.model(tensor)  # shape (1, embed_dim, H', W')\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "081dd2f4"
   },
   "source": [
    "\n",
    "## Integrating Anomaly Embeddings into FiftyOne\n",
    "\n",
    "Once we obtain embeddings from Padim, we will add them to our FiftyOne dataset.\n",
    "This allows us to:\n",
    "- Perform **similarity searches** based on anomaly scores.\n",
    "- Compare normal vs. abnormal sample distributions.\n",
    "- Leverage **FiftyOne App** to inspect anomalies.\n",
    "\n",
    "```python\n",
    "import fiftyone as fo\n",
    "\n",
    "dataset = fo.Dataset(\"object_from_mvtec_ad\")\n",
    "\n",
    "# Add embeddings to each sample\n",
    "for sample in dataset:\n",
    "    ...\n",
    "    # Convert to CPU NumPy for storage\n",
    "    embedding_1d = patch_embedding.squeeze(0).cpu().numpy()  # shape (D,)\n",
    "\n",
    "    # Store as a list in a new field\n",
    "    sample[\"embedding\"] = embedding_1d.tolist()\n",
    "    sample.save()\n",
    "    ...\n",
    "```\n",
    "**Relevant Documentation:** [Adding Custom Fields to FiftyOne Datasets](https://docs.voxel51.com/user_guide/using_datasets.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eELldphee5ko"
   },
   "source": [
    "## Selecting object from MVTec AD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1759167528777,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "9XsWx_Q9e5ko",
    "outputId": "40539ff5-d6a9-4894-cc91-aa06aebf6afc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        mvtec-bottle\n",
      "Media type:  image\n",
      "Num samples: 292\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    category:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    defect:           fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    split:            fiftyone.core.fields.StringField\n",
      "    defect_mask:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Segmentation)\n"
     ]
    }
   ],
   "source": [
    "from fiftyone import ViewField as F # helper for defining views\n",
    "\n",
    "## get the test split of the dataset\n",
    "test_split = dataset.match(F(\"category.label\") == 'bottle')\n",
    "\n",
    "# Clone the dataset into a new one called \"mvtec_bottle\"\n",
    "mvtec_bottle = test_split.clone(\"mvtec-bottle\", persistent=True)\n",
    "\n",
    "print(mvtec_bottle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1759167531860,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "YCumHe6oe5ko",
    "outputId": "3ecca104-0052-4c3e-8d70-7be7033cd8e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        MVTec_AD\n",
      "Media type:  image\n",
      "Num samples: 5354\n",
      "Persistent:  False\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    category:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    defect:           fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    split:            fiftyone.core.fields.StringField\n",
      "    defect_mask:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Segmentation)\n",
      "Name:        mvtec-bottle\n",
      "Media type:  image\n",
      "Num samples: 292\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    category:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    defect:           fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    split:            fiftyone.core.fields.StringField\n",
      "    defect_mask:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Segmentation)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(mvtec_bottle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjfi5ANqe5kp"
   },
   "source": [
    "## Calculating Embeddings using Inference with Padim Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 58899,
     "status": "ok",
     "timestamp": 1759167594669,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "n65Hq_Hke5kp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "for sample in mvtec_bottle:\n",
    "    # Load the image via PIL\n",
    "    pil_image = Image.open(sample.filepath).convert(\"RGB\")\n",
    "\n",
    "    # Apply your transform\n",
    "    input_tensor = transform(pil_image).unsqueeze(0)  # shape (1, C, H, W)\n",
    "\n",
    "    # Compute patch embeddings in train mode\n",
    "    with torch.no_grad():\n",
    "        patch_embedding = padim.model(input_tensor)  # shape (1, D, H', W')\n",
    "\n",
    "    # Optional: flatten or pool across spatial dims\n",
    "    # Here we use mean pooling to get a (1, D) vector\n",
    "    patch_embedding = patch_embedding.mean(dim=[2, 3])  # shape (1, D)\n",
    "\n",
    "    # Convert to CPU NumPy for storage\n",
    "    embedding_1d = patch_embedding.squeeze(0).cpu().numpy()  # shape (D,)\n",
    "\n",
    "    # Store as a list in a new field\n",
    "    sample[\"embedding\"] = embedding_1d.tolist()\n",
    "    sample.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seyjv47oe5kp"
   },
   "source": [
    "## Visualizing Embeddings in FiftyOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17822,
     "status": "ok",
     "timestamp": 1759167616965,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "SUp8KQSle5kp",
    "outputId": "bb048dd5-9038-4234-dafa-3f078e24f4c3"
   },
   "outputs": [],
   "source": [
    "from fiftyone.brain import compute_visualization\n",
    "\n",
    "# This will perform PCA on the \"embedding\" field\n",
    "compute_visualization(\n",
    "    mvtec_bottle,\n",
    "    embeddings=\"padin_emb\",\n",
    "    brain_key=\"embedding_pca\",\n",
    "    method=\"pca\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1759167619023,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "DHancl-He5kp",
    "outputId": "844c6fe5-f661-4a1c-a23d-c837a7d35470"
   },
   "outputs": [],
   "source": [
    "mvtec_bottle.reload()\n",
    "print(mvtec_bottle)\n",
    "print(mvtec_bottle.last())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8MU74QSe5kp"
   },
   "outputs": [],
   "source": [
    "session = fo.launch_app(mvtec_bottle, port=5154, auto=False)\n",
    "print(session.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsjgAh7Ze5kp"
   },
   "source": [
    "![embedding_anomaly](https://cdn.voxel51.com/getting_started_manufacturing/notebook4/embedding_annomaly.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "428fe1d7"
   },
   "source": [
    "### Next Steps:\n",
    "Try using different anomaly detection models from Anomalib and compare their embeddings with FiftyOne's visualization tools! 🚀\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/voxel51/fiftyone/blob/main/docs/source/getting_started/manufacturing/04_custom_embeddings.ipynb",
     "timestamp": 1759166344817
    }
   ]
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "15af93f8efd745fbb9a0af3f14f69b06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e2d3d951d044a909053b095711e701a",
      "placeholder": "​",
      "style": "IPY_MODEL_d9954b4f10b9445d9ae9f22b7e7c044c",
      "value": " 46.8M/46.8M [00:00&lt;00:00, 305MB/s]"
     }
    },
    "19435e821d624c4691c535a7cbd8f0e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "256a7852527e43f7b6cd09559e70b323": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "490f64f581684790b7a1e8307d58f68e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7f734f4e568a496f85019f1526b3defa",
       "IPY_MODEL_5eda7ab8d3e74b3182f551f165ea1355",
       "IPY_MODEL_15af93f8efd745fbb9a0af3f14f69b06"
      ],
      "layout": "IPY_MODEL_256a7852527e43f7b6cd09559e70b323"
     }
    },
    "5eda7ab8d3e74b3182f551f165ea1355": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_906dea5e54434f8a993a3a0753a65df5",
      "max": 46807446,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ada86e09bddc459591dfdacaf4efbfcb",
      "value": 46807446
     }
    },
    "6e2d3d951d044a909053b095711e701a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f734f4e568a496f85019f1526b3defa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1eb541071354357bd1a15aec2cd6f2e",
      "placeholder": "​",
      "style": "IPY_MODEL_19435e821d624c4691c535a7cbd8f0e1",
      "value": "model.safetensors: 100%"
     }
    },
    "906dea5e54434f8a993a3a0753a65df5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ada86e09bddc459591dfdacaf4efbfcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d1eb541071354357bd1a15aec2cd6f2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9954b4f10b9445d9ae9f22b7e7c044c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
