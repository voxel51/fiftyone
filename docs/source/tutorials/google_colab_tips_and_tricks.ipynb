{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d148e24-9b24-4f0e-ac2a-592f4477b8b2",
   "metadata": {
    "id": "2d148e24-9b24-4f0e-ac2a-592f4477b8b2"
   },
   "source": "# Tips and Tricks for Using FiftyOne in Google Colab\n\nWorking with FiftyOne in Google Colab presents unique challenges: temporary instances that lose your data, installation overhead on every restart, and the need to manage datasets across sessions. This notebook shares practical techniques to make your FiftyOne workflow in Colab faster, more reliable, and reproducible.\n\nWe'll cover the following concepts:\n\n- Installing FiftyOne efficiently using modern tools\n- Persisting datasets, models, and configurations across sessions with Google Drive\n- Sharing datasets with collaborators\n- Leveraging GPU acceleration for faster inference\n- Managing the FiftyOne App for a better development experience\n\n**So, what's the takeaway?**\n\nThese patterns apply beyond FiftyOne. The techniques for managing data persistence, sharing resources, and optimizing compute translate to other ML workflows in Colab.\n\n## Setup\n\nTo follow this tutorial, you'll need a Google account with sufficient space on Google Drive (approximately 1 GB)."
  },
  {
   "cell_type": "markdown",
   "id": "9b1c73a8-6f51-460f-90e6-a07802830f3c",
   "metadata": {
    "id": "9b1c73a8-6f51-460f-90e6-a07802830f3c"
   },
   "source": "## Tip 1: Fast and clean FiftyOne installation\n\nUsing `uv` for package installation and `%%capture` to suppress output creates clean and efficient Colab notebooks.\n\nIn Google Colab, the virtual machine instance is temporary. When you close your browser tab or the notebook becomes idle for too long, the instance is recycled and all installed packages are lost. Having a quick way to re-install libraries like FiftyOne is valuable.\n\n### Why use uv?\n\n[uv](https://github.com/astral-sh/uv) is a modern, fast Python package installer and resolver designed to be significantly quicker than traditional tools like `pip` or `conda`. This is useful in Colab notebooks since they need to be re-configured each time you start a new session.\n\n### Suppressing installation output\n\nThe `%%capture` magic command suppresses the standard output and standard error streams of a cell. When installing packages, the output can be verbose. Using `%%capture` keeps your notebook clean and focused on results.\n\n### Specifying package versions\n\nIt's good practice to make the version of your libraries explicit. This is crucial for reproducibilityâ€”different versions can have API changes or different dependencies. By specifying the version, you ensure that anyone running your notebook in the future uses the exact same environment."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c0e5a-2c8c-4fcc-ac6f-0046e7f8b919",
   "metadata": {
    "id": "2e3c0e5a-2c8c-4fcc-ac6f-0046e7f8b919"
   },
   "outputs": [],
   "source": [
    "# We use %%capture to avoid polluting the notebook with the install trace\n",
    "%%capture\n",
    "!uv pip install fiftyone==1.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8b4447-b82b-4265-a864-46c593259b32",
   "metadata": {
    "id": "1d8b4447-b82b-4265-a864-46c593259b32"
   },
   "source": "Import FiftyOne:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764d3e51-c36b-4886-9878-5776d5483a91",
   "metadata": {
    "id": "764d3e51-c36b-4886-9878-5776d5483a91"
   },
   "outputs": [],
   "source": [
    "import fiftyone as fo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04968cd-7058-4775-8167-270f9bd36474",
   "metadata": {
    "id": "d04968cd-7058-4775-8167-270f9bd36474"
   },
   "source": "Verify the installed version:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ed28a7-743a-4467-b508-3a1378f8c7de",
   "metadata": {
    "id": "31ed28a7-743a-4467-b508-3a1378f8c7de"
   },
   "outputs": [],
   "source": [
    "print(f\"FiftyOne version installed: {fo.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f0962b-7b0d-4da4-8ac9-8b89e13d9419",
   "metadata": {
    "id": "f5f0962b-7b0d-4da4-8ac9-8b89e13d9419"
   },
   "source": "## Tip 2: Persistent storage with Google Drive\n\nColab instances are recycled after a period of inactivity (usually around 90 minutes) or when you close your browser tab. Instances also have a maximum lifetime (currently 12 hours), after which they are recycled. Any data not saved to persistent storage will be lost.\n\nUsing Google Drive as persistent storage ensures your datasets, models, and work are preserved across sessions. Note that if you share your notebook with collaborators, they will only be able to access data in your Drive that you've granted them access to."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67c519c-07f9-46c7-9523-c3e034907921",
   "metadata": {
    "id": "d67c519c-07f9-46c7-9523-c3e034907921"
   },
   "outputs": [],
   "source": [
    "# You will be asked to authorize access to Drive after running this.\n",
    "# Note that this connects to your own Google Drive account.\n",
    "# It doesn't connect to folders from others unless they have been shared with you.\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139389c-0b82-4fcf-b676-e13d4206584c",
   "metadata": {
    "id": "3139389c-0b82-4fcf-b676-e13d4206584c"
   },
   "source": "Create a directory for your FiftyOne data:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a5a92-f047-4952-b88d-e0dfc833bb9b",
   "metadata": {
    "id": "766a5a92-f047-4952-b88d-e0dfc833bb9b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "# Notice that this is a Google Drive path\n",
    "save_path = Path('/gdrive/MyDrive/fiftyone_dataset_curation')\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b833215-ed16-43b6-ae3a-b857502787e9",
   "metadata": {
    "id": "7b833215-ed16-43b6-ae3a-b857502787e9"
   },
   "source": "Configure the MongoDB database location for FiftyOne:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91cd8b3-3a11-479c-9c90-b1ff889028df",
   "metadata": {
    "id": "a91cd8b3-3a11-479c-9c90-b1ff889028df"
   },
   "outputs": [],
   "source": [
    "# path to the MongoDB database\n",
    "database_path = save_path / \"mongodb\"\n",
    "os.makedirs(database_path, exist_ok=True)\n",
    "fo.config.database_dir = str(database_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893d5673-cdb0-40e1-ad14-ed4e287b3558",
   "metadata": {
    "id": "893d5673-cdb0-40e1-ad14-ed4e287b3558"
   },
   "source": "Load a sample dataset from the FiftyOne Dataset Zoo:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f215d8-6b21-4d37-af31-698f12a3d02a",
   "metadata": {
    "id": "81f215d8-6b21-4d37-af31-698f12a3d02a"
   },
   "outputs": [],
   "source": [
    "import fiftyone.zoo as foz\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split=\"validation\",\n",
    "    max_samples=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e944cd-9f79-4da3-b430-c3d325785a97",
   "metadata": {
    "id": "b3e944cd-9f79-4da3-b430-c3d325785a97"
   },
   "source": "Export the dataset to Google Drive:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7ab45-b467-4e92-a9b0-9b0d3d5ac244",
   "metadata": {
    "id": "b1a7ab45-b467-4e92-a9b0-9b0d3d5ac244"
   },
   "outputs": [],
   "source": [
    "# Export the dataset to a folder\n",
    "export_dir = save_path / \"coco-2017\"\n",
    "dataset.export(\n",
    "    export_dir=str(export_dir),\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    "     # set to True to export the original images alongside annotations\n",
    "    export_media=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b109e-1e9a-4c2f-bcfb-489956461c28",
   "metadata": {
    "id": "3e9b109e-1e9a-4c2f-bcfb-489956461c28"
   },
   "source": "Reload the dataset from Drive in a future session:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f6de1-cd7d-4467-ad5f-d22567df4d2d",
   "metadata": {
    "id": "c76f6de1-cd7d-4467-ad5f-d22567df4d2d"
   },
   "outputs": [],
   "source": [
    "reloaded_dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=export_dir,\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FzVR7Jfdq5_q",
   "metadata": {
    "id": "FzVR7Jfdq5_q"
   },
   "source": "## Tip 3: Downloading shared folders with gdown\n\nWhen a dataset is shared as a Google Drive folder, [gdown](https://github.com/wkentaro/gdown) provides a convenient way to download files directly from public Google Drive links. This automates the download process and can be included directly in your notebook for reproducibility."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rlf8x3z9q-AE",
   "metadata": {
    "id": "rlf8x3z9q-AE"
   },
   "outputs": [],
   "source": [
    "# We use %%capture to avoid polluting the notebook with the install trace\n",
    "%%capture\n",
    "!uv pip install gdown==5.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wOR534Y-rCB7",
   "metadata": {
    "id": "wOR534Y-rCB7"
   },
   "source": "Define the URL of the shared folder and specify a local path. We'll download the same COCO-2017 sample dataset exported earlier.\n\nPublic access link: https://drive.google.com/drive/folders/1G6JKGm0sy5d5ViEpDktXMxIqq5cl2Nrc?usp=drive_link"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BrgOkWKrrFT4",
   "metadata": {
    "id": "BrgOkWKrrFT4"
   },
   "outputs": [],
   "source": [
    "# This assumes 'save_path' is defined from a previous cell.\n",
    "# Let's ensure it exists.\n",
    "save_path = Path('/gdrive/MyDrive/fiftyone_dataset_curation')\n",
    "download_output_path = save_path / \"gdown_downloads\"\n",
    "os.makedirs(download_output_path, exist_ok=True)\n",
    "\n",
    "# The public Google Drive folder URL for the COCO-2017 samples\n",
    "folder_url = \"https://drive.google.com/drive/folders/1G6JKGm0sy5d5ViEpDktXMxIqq5cl2Nrc?usp=drive_link\"\n",
    "\n",
    "# Use gdown to download the entire folder.\n",
    "# The --folder flag specifies that we are downloading a folder.\n",
    "# The -O flag sets the output directory.\n",
    "!gdown --folder \"{folder_url}\" -O \"{download_output_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K0K8M0GLrIWs",
   "metadata": {
    "id": "K0K8M0GLrIWs"
   },
   "source": "You may encounter a limit when downloading folders with many files:\n\n```bash\nThe gdrive folder with url: https://drive.google.com/drive/folders/1fe\n\tUZBqLJm_2OoxLKTxV53SGPZvUYPa49?hl=en has more than 50 files, gdrive\n\tcan't download more than this limit.\n```"
  },
  {
   "cell_type": "markdown",
   "id": "3Gx_092yrNNj",
   "metadata": {
    "id": "3Gx_092yrNNj"
   },
   "source": "To bypass this limit, zip the folder first and share the zip file:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iPYRZhhtrRKE",
   "metadata": {
    "id": "iPYRZhhtrRKE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Define the path to the folder you want to zip\n",
    "folder_to_zip = '/gdrive/MyDrive/fiftyone_dataset_curation/coco-2017'\n",
    "\n",
    "# Define the name and path for the output zip file\n",
    "output_zip_file = '/gdrive/MyDrive/fiftyone_dataset_curation/coco-2017.zip'\n",
    "\n",
    "# Create a ZipFile object in write mode\n",
    "with zipfile.ZipFile(output_zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    # Walk through all the files and subdirectories in the folder\n",
    "    for root, dirs, files in os.walk(folder_to_zip):\n",
    "        for file in files:\n",
    "            # Create the full path to the file\n",
    "            file_path = os.path.join(root, file)\n",
    "            # Add the file to the zip archive, preserving the directory structure\n",
    "            zipf.write(file_path, os.path.relpath(file_path, folder_to_zip))\n",
    "\n",
    "print(f\"Folder '{folder_to_zip}' successfully zipped to '{output_zip_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x2Xcy5acrWP0",
   "metadata": {
    "id": "x2Xcy5acrWP0"
   },
   "source": "Create a new shared link for the zip file:\n\n![create_sharing_link](https://cdn.voxel51.com/getting_started_colab_tips/notebook2/create_sharing_link.webp)"
  },
  {
   "cell_type": "markdown",
   "id": "Kc8E2qkFvplZ",
   "metadata": {
    "id": "Kc8E2qkFvplZ"
   },
   "source": "Click \"Manage Access\" and set \"Everyone\" to \"Viewer\" permission to share the file publicly:"
  },
  {
   "cell_type": "markdown",
   "id": "mXQNQPWtvbZ2",
   "metadata": {
    "id": "mXQNQPWtvbZ2"
   },
   "source": [
    "![manage_access](https://cdn.voxel51.com/getting_started_colab_tips/notebook2/manage_access.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j7llYZxrwRZ5",
   "metadata": {
    "id": "j7llYZxrwRZ5"
   },
   "source": "Download the zip file and unzip it:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nDAl_7-bwmxC",
   "metadata": {
    "id": "nDAl_7-bwmxC"
   },
   "outputs": [],
   "source": [
    "# The public Google Drive folder URL for the COCO-2017 samples\n",
    "file_url = \"https://drive.google.com/file/d/1UyL0clgoIPSYDWHlPjLP0IPZoFRQQJDE/view?usp=drive_link\"\n",
    "\n",
    "# Use gdown to download the entire file.\n",
    "!gdown \"{file_url}\" -O \"{download_output_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KiKWDee60eem",
   "metadata": {
    "id": "KiKWDee60eem"
   },
   "source": "Here's the complete workflow in Python:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8Tj9vDEr0hID",
   "metadata": {
    "id": "8Tj9vDEr0hID"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import fiftyone as fo\n",
    "\n",
    "# --- 1. Setup Paths ---\n",
    "# This assumes 'save_path' is defined from a previous cell.\n",
    "# Let's ensure it exists.\n",
    "save_path = Path('/gdrive/MyDrive/fiftyone_dataset_curation')\n",
    "download_dir = save_path / \"gdown_downloads\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# Define the full path for the downloaded zip file\n",
    "zip_file_path = download_dir / \"coco_samples_dataset.zip\"\n",
    "\n",
    "# Define the directory where the contents will be unzipped\n",
    "unzip_dir = download_dir / \"coco_samples_unzipped\"\n",
    "os.makedirs(unzip_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- 2. Download the ZIP file from Google Drive ---\n",
    "# The public Google Drive file URL for the zipped COCO-2017 samples\n",
    "file_url = \"https://drive.google.com/file/d/1UyL0clgoIPSYDWHlPjLP0IPZoFRQQJDE/view?usp=drive_link\"\n",
    "\n",
    "print(f\"Downloading dataset from Google Drive to '{zip_file_path}'...\")\n",
    "# Use gdown.download to fetch the file\n",
    "gdown.download(url=file_url, output=str(zip_file_path), quiet=False)\n",
    "print(\"Download complete.\")\n",
    "\n",
    "\n",
    "# --- 3. Unzip the File using the `zipfile` library ---\n",
    "print(f\"Unzipping '{zip_file_path}' to '{unzip_dir}'...\")\n",
    "\n",
    "# Use a 'with' statement to safely open and extract the zip archive\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(unzip_dir)\n",
    "    print(\"Unzipping successful.\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(\"Error: The downloaded file is not a valid zip file or is corrupted.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during unzipping: {e}\")\n",
    "\n",
    "\n",
    "# --- 4. Load the dataset into FiftyOne ---\n",
    "# The directory containing the unzipped FiftyOne dataset\n",
    "# Note: The actual dataset might be in a subdirectory within `unzip_dir`.\n",
    "# For this specific zip file, the data is in the root of the unzipped folder.\n",
    "dataset_dir = unzip_dir\n",
    "\n",
    "print(f\"Loading FiftyOne dataset from '{dataset_dir}'...\")\n",
    "\n",
    "# Check if the directory exists and appears to be a FiftyOne dataset\n",
    "if (Path(dataset_dir) / \"samples.json\").exists():\n",
    "    # Use Dataset.from_dir to load the dataset from its source directory\n",
    "    dataset = fo.Dataset.from_dir(\n",
    "        dataset_dir=str(dataset_dir),\n",
    "        dataset_type=fo.types.FiftyOneDataset,\n",
    "        name=\"coco-samples-from-drive\" # Give the dataset a unique name\n",
    "    )\n",
    "\n",
    "    print(\"\\nDataset loaded successfully!\")\n",
    "    print(dataset)\n",
    "\n",
    "    # You can now work with the dataset, for example, launch the App\n",
    "    # session = fo.launch_app(dataset)\n",
    "    # print(session.url)\n",
    "else:\n",
    "    print(f\"Error: Could not find a valid FiftyOne dataset at '{dataset_dir}'.\")\n",
    "    print(\"Please check the contents of the unzipped folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PdZbVrwlx9Z_",
   "metadata": {
    "id": "PdZbVrwlx9Z_"
   },
   "source": "You may encounter rate limiting:\n\n```bash\nCannot retrieve the folder information from the link. You may need to\n\tchange the permission to 'Anyone with the link', or have had many\n\taccesses.\n```\n\nWhen this happens, consider using Drive shortcuts instead (see Tip 4)."
  },
  {
   "cell_type": "markdown",
   "id": "4b5d2780-b2dd-41e9-91c9-5a50785f8abf",
   "metadata": {
    "id": "4b5d2780-b2dd-41e9-91c9-5a50785f8abf"
   },
   "source": "## Tip 4: Instant dataset sharing with Drive shortcuts\n\nAdding a shortcut from a shared Google Drive folder to your own account provides fast access to data **without downloading, compressing, or decompressing**. This is more immediate than using gdown.\n\nYou can try the following steps using this public access link to COCO-2017 samples: https://drive.google.com/drive/folders/1G6JKGm0sy5d5ViEpDktXMxIqq5cl2Nrc?usp=sharing\n\n### Creating a shortcut\n\n1. Open [drive.google.com](https://drive.google.com) and sign in\n2. (Optional) If the folder was shared via invitation, find it under \"Shared with me\"\n3. Right-click on the folder and select **Organize > Add shortcut to Drive**\n\n![add_shortcut](https://cdn.voxel51.com/getting_started_colab_tips/notebook2/add_shortcut.webp)\n\n4. Select a location (e.g., \"My Drive\") and click **Add shortcut**\n5. Access your shortcutâ€”it will be marked with a small arrow icon\n\nYou can then reference this folder in your code:\n\n```python\nfrom pathlib import Path\nimport os\npath = Path(\"/gdrive/MyDrive/<folder_name>\")\nos.listdir(path)\n```\n\nShortcuts are pointers to the original folderâ€”they don't make copies or use your storage quota. Any changes to files within the shortcut are reflected in the original folder.\n\n### Configuring FiftyOne paths on Drive\n\nSave your FiftyOne downloads, models, and MongoDB database to Drive by modifying the configuration:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8df589-9b93-4a11-a83d-3652c4168c92",
   "metadata": {
    "id": "1d8df589-9b93-4a11-a83d-3652c4168c92"
   },
   "outputs": [],
   "source": [
    "# Check the state of fo.config before doing any modification\n",
    "print(fo.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439241b7-6df7-4972-8efc-1cdca736c96a",
   "metadata": {
    "id": "439241b7-6df7-4972-8efc-1cdca736c96a"
   },
   "outputs": [],
   "source": [
    "# Where we will download the data when using the FiftyOne dataset zoo\n",
    "# https://docs.voxel51.com/dataset_zoo/index.html\n",
    "dataset_zoo_path = save_path / \"fo_dataset_zoo\"\n",
    "os.makedirs(dataset_zoo_path, exist_ok=True)\n",
    "fo.config.dataset_zoo_dir = str(dataset_zoo_path)\n",
    "\n",
    "# path to the MongoDB database\n",
    "database_path = save_path / \"mongodb\"\n",
    "os.makedirs(database_path, exist_ok=True)\n",
    "fo.config.database_dir = str(database_path)\n",
    "\n",
    "models_path = str(save_path / \"models\")\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "fo.config.model_zoo_dir = models_path\n",
    "\n",
    "model = foz.load_zoo_model(\"clip-vit-base32-torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408018ff-a040-45d2-a72d-45c55536417f",
   "metadata": {
    "id": "408018ff-a040-45d2-a72d-45c55536417f"
   },
   "source": "## Tip 5: Secure API access with Colab Secrets\n\nAdding tokens (like HuggingFace) as secrets in Google Colab allows you to share your notebooks without exposing personal credentials.\n\n### Why you need a HuggingFace token\n\n- **Access gated models**: Many models on HuggingFace require agreeing to terms before downloading. Your token verifies permissions.\n- **Avoid rate limiting**: Authenticated requests have higher download limits.\n- **Upload your work**: Upload and manage models and datasets on the Hub.\n\n### Setting up your token\n\n1. Create an account at [huggingface.co](https://huggingface.co/)\n2. Go to **Settings > Access Tokens** and create a new token with \"Write\" role\n3. In Colab, click the **key icon** (ðŸ”‘) in the left sidebar\n4. Add a new secret named `HUGGINGFACE_TOKEN` with your token value\n5. Enable \"Notebook access\"\n\n### Using the token\n\n```python\nimport os\nfrom google.colab import userdata\n\nos.environ[\"HUGGINGFACE_TOKEN\"] = userdata.get('HUGGINGFACE_TOKEN')\n```\n\n**Security tip**: Never expose tokens in plain text. If compromised, revoke immediately in your HuggingFace settings.\n\n### Loading datasets from HuggingFace"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c10d32-d1d8-4f80-873b-e8557b458d92",
   "metadata": {
    "id": "e7c10d32-d1d8-4f80-873b-e8557b458d92"
   },
   "outputs": [],
   "source": [
    "from fiftyone.utils.huggingface import load_from_hub\n",
    "\n",
    "other_datasets_path = save_path / \"other_datasets\"\n",
    "os.makedirs(other_datasets_path, exist_ok=True)\n",
    "fo.config.default_dataset_dir = str(other_datasets_path)\n",
    "\n",
    "curated_mnist_dataset = load_from_hub(\"Voxel51/curated-mnist\",\n",
    "                                       max_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87550f24-6997-40fd-b3f5-62d3a1f80879",
   "metadata": {
    "id": "87550f24-6997-40fd-b3f5-62d3a1f80879"
   },
   "source": "## Tip 6: Launching the FiftyOne App in a separate tab\n\nLaunching the FiftyOne App in a separate browser tab provides a full-window view, which is often more convenient than embedding it within a notebook cell."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90a2c07-e815-46f9-8d19-4f7f457cc037",
   "metadata": {
    "id": "a90a2c07-e815-46f9-8d19-4f7f457cc037"
   },
   "outputs": [],
   "source": [
    "# Passing auto=False prevents the app from launch on its own notebook cell\n",
    "session = fo.launch_app(dataset, auto=False)\n",
    "# print session.url gives us a nice URL that we can click on ;)\n",
    "print(f\"Just click here to get to the app (whenever you want, no auto launch) {session.url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kXY9SmeFzAuT",
   "metadata": {
    "id": "kXY9SmeFzAuT"
   },
   "source": [
    "![full_window_view](https://cdn.voxel51.com/getting_started_colab_tips/notebook2/full_window_view.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ff89o5Wjr8eP",
   "metadata": {
    "id": "Ff89o5Wjr8eP"
   },
   "source": "Alternatively, `session.open_tab()` opens a new tab automatically, though printing the URL gives you more control over when to access the App."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4sFS6zoDr1zt",
   "metadata": {
    "id": "4sFS6zoDr1zt"
   },
   "outputs": [],
   "source": [
    "# session.open_tab() is another option, we just don't get to see the URL here\n",
    "#session.open_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b207eb-1215-4752-b883-9bb6d8928014",
   "metadata": {
    "id": "59b207eb-1215-4752-b883-9bb6d8928014"
   },
   "source": "## Tip 7: Managing a single App instance\n\nEach call to `fo.launch_app()` launches a new server process. While you can run multiple apps, it's best to manage a single instance to conserve resources and avoid confusion. If you see the FiftyOne App \"flickering,\" it's often because two instances are running simultaneously.\n\nStore the returned `session` object to control the app programmatically. If you call `fo.launch_app()` again with an existing session, FiftyOne will return a handle to the existing session without creating a new one."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da14ab77-8d26-4740-b608-cc1840dd30f5",
   "metadata": {
    "id": "da14ab77-8d26-4740-b608-cc1840dd30f5"
   },
   "outputs": [],
   "source": [
    "# The dataset is already loaded from a previous cell\n",
    "# dataset = foz.load_zoo_dataset(\"coco-2017\", split=\"validation\", max_samples=200)\n",
    "\n",
    "# If it's flickering it's because we have already called fo.launch_app() inside the notebook\n",
    "# This will gracefully shut down the App server associated with the previous session\n",
    "session.close()\n",
    "\n",
    "# Launch the app and store the session.\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e7cd0-02ba-4b8c-b690-b964344cd35b",
   "metadata": {
    "id": "678e7cd0-02ba-4b8c-b690-b964344cd35b"
   },
   "source": "Use the session object to update the view without relaunching:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b1a20a-6663-4702-861c-8b2014605934",
   "metadata": {
    "id": "97b1a20a-6663-4702-861c-8b2014605934"
   },
   "outputs": [],
   "source": [
    "from fiftyone import ViewField as F\n",
    "\n",
    "dog_view = dataset.filter_labels(\"ground_truth\", F(\"label\") == \"dog\")\n",
    "session.view = dog_view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5f747-063a-4424-8f43-6d1a9386d494",
   "metadata": {
    "id": "55f5f747-063a-4424-8f43-6d1a9386d494"
   },
   "source": "If you close the App's cell or tab, the underlying Python process continues running. You can reopen a tab to the App's URL anytime."
  },
  {
   "cell_type": "markdown",
   "id": "0ac877e3-0c4a-4d7a-b9c1-4b15096fd5d2",
   "metadata": {
    "id": "0ac877e3-0c4a-4d7a-b9c1-4b15096fd5d2"
   },
   "source": "## Tip 8: GPU acceleration for faster inference\n\nEnable GPU acceleration to significantly speed up inference and computations. Google Colab provides free access to GPUs:\n\n```\nRuntime > Change Runtime Type > T4 GPU\n```\n\nThis provides an NVIDIA T4 GPU with approximately 16 GB of VRAM, making embedding computation and model inference much faster."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ac311-b0e5-4f32-8df9-51a441315e12",
   "metadata": {
    "id": "017ac311-b0e5-4f32-8df9-51a441315e12"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# Check if the GPU is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cVZq4srmqfsf",
   "metadata": {
    "id": "cVZq4srmqfsf"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import fiftyone.brain as fob\n",
    "\n",
    "# Helper: measure time for computing embeddings into a field\n",
    "def time_compute_embeddings_and_project(model, label=\"gpu\"):\n",
    "    start = time.time()\n",
    "    # Use Brain to both compute embeddings and reduce dimensionality\n",
    "    res = fob.compute_visualization(\n",
    "        dataset,\n",
    "        model=model,\n",
    "        embeddings=\"clip_embeddings_\" + label,\n",
    "        brain_key=\"vis_\" + label,\n",
    "        method='pca',\n",
    "        batch_size=16,\n",
    "    )\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "\n",
    "# Load CLIP (OpenAI ViT-B/32) from the model zoo\n",
    "clip_model = foz.load_zoo_model(\"clip-vit-base32-torch\")\n",
    "print(\"Model has embeddings:\", getattr(clip_model, \"has_embeddings\", None))\n",
    "\n",
    "# Benchmark on GPU (if available)\n",
    "gpu_time = None\n",
    "if torch.cuda.is_available():\n",
    "    # Many FiftyOne zoo models run on GPU automatically if available;\n",
    "    # timing reflects GPU execution.\n",
    "    gpu_time = time_compute_embeddings_and_project(clip_model, label=\"gpu\")\n",
    "    print(f\"GPU time (s): {gpu_time:.2f}\")\n",
    "\n",
    "# Force CPU run by moving model to CPU (and/or disabling CUDA)\n",
    "# Depending on environment, you may need to ensure the model runs on CPU.\n",
    "# Re-load a fresh model instance to avoid device cross-talk\n",
    "clip_model_cpu = foz.load_zoo_model(\"clip-vit-base32-torch\")\n",
    "# If the wrapped model exposes .cuda()/.cpu(), it will be set appropriately by the integration.\n",
    "# Here we simply assume CPU because no CUDA ops are used when CUDA is unavailable.\n",
    "# If your environment auto-selects GPU, set CUDA_VISIBLE_DEVICES=\"\" before launching Python\n",
    "cpu_time = time_compute_embeddings_and_project(clip_model_cpu, label=\"cpu\")\n",
    "print(f\"CPU time (s): {cpu_time:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67041a7d-b6da-4903-885f-7589de648341",
   "metadata": {
    "id": "67041a7d-b6da-4903-885f-7589de648341"
   },
   "source": "## Tip 9: High-RAM runtime for large datasets\n\nWhen working with large datasets or high-resolution images, the standard Colab runtime (approximately 12 GB RAM) may be insufficient. Colab Pro offers a High-RAM runtime with approximately 25 GB or more:\n\n```\nRuntime > Change Runtime Type > Runtime shape > High-RAM\n```\n\nThis is useful when loading many samples into FiftyOne, computing embeddings for entire datasets, or performing other memory-intensive operations.\n\nFiftyOne remains responsive even on low resources, but larger datasets benefit from extra memory:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4221d6f-2391-4960-93ed-303c73489849",
   "metadata": {
    "id": "e4221d6f-2391-4960-93ed-303c73489849"
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "# Check available RAM\n",
    "total_ram_bytes = psutil.virtual_memory().total\n",
    "# Convert 16GB to bytes\n",
    "sixteen_gb_bytes = 16 * 1024 * 1024 * 1024\n",
    "\n",
    "if total_ram_bytes > sixteen_gb_bytes:\n",
    "    try:\n",
    "        big_dataset = foz.load_zoo_dataset(\n",
    "            \"coco-2017\",\n",
    "            split=\"validation\",\n",
    "            max_samples=5000,  # Loading 5000 samples requires more memory\n",
    "        )\n",
    "        print(f\"Successfully loaded a larger dataset with {len(big_dataset)} samples.\")\n",
    "        # You can now launch the app with this larger dataset\n",
    "        # session = fo.launch_app(big_dataset)\n",
    "        # print(session.url)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"This may be due to insufficient RAM. Try switching to a High-RAM runtime.\")\n",
    "else:\n",
    "    print(\"Skipping loading the larger dataset: Insufficient RAM (less than 16GB) available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I5G_ssxD2yRl",
   "metadata": {
    "id": "I5G_ssxD2yRl"
   },
   "source": "## Tip 10: Rendering notebooks that fail on GitHub\n\nMany Jupyter notebooks produce artifacts that prevent proper rendering on GitHub previews:\n\n![invalid_notebook](https://cdn.voxel51.com/getting_started_colab_tips/notebook2/invalid_notebook.webp)\n\nExample of a notebook that doesn't render: https://github.com/andandandand/practical-computer-vision/blob/main/notebooks/Food_Dataset_Curation_with_Fiftyone.ipynb\n\nChange `github.com` to `githubtocolab.com` in the URL to render it immediately in Colab:\n\nhttps://githubtocolab.com/andandandand/practical-computer-vision/blob/main/notebooks/Food_Dataset_Curation_with_Fiftyone.ipynb"
  },
  {
   "cell_type": "markdown",
   "id": "R8QKGjHf3kB_",
   "metadata": {
    "id": "R8QKGjHf3kB_"
   },
   "source": [
    "![working_colab](https://cdn.voxel51.com/getting_started_colab_tips/notebook2/working_colab.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TsjcntVQi84d",
   "metadata": {
    "id": "TsjcntVQi84d"
   },
   "source": "## Summary\n\nThis tutorial covered techniques for working effectively with FiftyOne in Google Colab's temporary environment.\n\n**Installation and Setup**\n- Use `uv` for fast package installation\n- Apply `%%capture` to suppress verbose output\n- Pin explicit versions for reproducibility\n\n**Data Persistence**\n- Mount Google Drive to preserve datasets across sessions\n- Configure FiftyOne's MongoDB database to Drive storage paths\n- Export and import datasets using `fo.types.FiftyOneDataset`\n\n**Sharing and Collaboration**\n- Download shared folders with `gdown` (best for smaller datasets)\n- Use Drive shortcuts for instant access without downloading\n- Set proper permissions for collaborative access\n\n**App Management**\n- Launch with `auto=False` and print URLs for manual access\n- Manage a single session to prevent flickering\n- Close and reopen without data loss\n\n**Performance**\n- Enable T4 GPU runtime for faster inference\n- Use High-RAM runtime (25 GB+) for large datasets\n- Benchmark CPU vs GPU execution times\n\n**Additional Tips**\n- Use `githubtocolab.com` to render notebooks that fail on GitHub\n- Remember: 90-minute idle timeout, 12-hour maximum session lifetime"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}