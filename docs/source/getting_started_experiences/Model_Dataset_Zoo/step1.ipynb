{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecf2e51",
   "metadata": {},
   "source": [
    "# Getting Started with the FiftyOne Zoo - Dataset Zoo\n",
    "\n",
    "This experience introduces you to the core components of the FiftyOne Zoo:\n",
    "- The **Dataset Zoo** for accessing and exploring public datasets\n",
    "- The **Model Zoo** for running pre-trained models on your data\n",
    "- Creating your **own remotely-sourced datasets** for reuse and collaboration\n",
    "\n",
    "Whether you're a researcher, engineer, or educator, these tools help streamline your computer vision workflows in FiftyOne.\n",
    "\n",
    "> üí° Make sure to run `pip install fiftyone torch torchvision` before starting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup ---\n",
    "#!pip install fiftyone\n",
    "#!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FiftyOne Zoo: A Hub for Datasets and Models\n",
    "\n",
    "FiftyOne Zoo provides easy access to a vast collection of pre-built datasets and pre-trained models. This notebook will guide you through exploring and using these resources.\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "* **Dataset Zoo:** Offers a wide range of computer vision datasets, ready for immediate use.\n",
    "* **Model Zoo:** Provides pre-trained models for various tasks, enabling quick experimentation and deployment.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Zoo\n",
    "\n",
    "### Exploring the Dataset Zoo\n",
    "\n",
    "The Dataset Zoo simplifies the process of loading and working with popular datasets.\n",
    "\n",
    "#### Listing Available Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Datasets:\n",
      "- activitynet-100\n",
      "- activitynet-200\n",
      "- bdd100k\n",
      "- caltech101\n",
      "- caltech256\n",
      "- cifar10\n",
      "- cifar100\n",
      "- cityscapes\n",
      "- coco-2014\n",
      "- coco-2017\n",
      "- fashion-mnist\n",
      "- fiw\n",
      "- hmdb51\n",
      "- imagenet-2012\n",
      "- imagenet-sample\n",
      "- kinetics-400\n",
      "- kinetics-600\n",
      "- kinetics-700\n",
      "- kinetics-700-2020\n",
      "- kitti\n",
      "- kitti-multiview\n",
      "- lfw\n",
      "- mnist\n",
      "- open-images-v6\n",
      "- open-images-v7\n",
      "- places\n",
      "- quickstart\n",
      "- quickstart-3d\n",
      "- quickstart-geo\n",
      "- quickstart-groups\n",
      "- quickstart-video\n",
      "- sama-coco\n",
      "- ucf101\n",
      "- voc-2007\n",
      "- voc-2012\n"
     ]
    }
   ],
   "source": [
    "print(\"Available Datasets:\")\n",
    "for dataset_name in foz.list_zoo_datasets():\n",
    "    print(f\"- {dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available Datasets:\n",
    "- activitynet-100\n",
    "- activitynet-200\n",
    "- bdd100k\n",
    "- caltech101\n",
    "- caltech256\n",
    "- cifar10\n",
    "- cifar100\n",
    "- cityscapes\n",
    "- coco-2014\n",
    "- coco-2017\n",
    "- fashion-mnist\n",
    "- fiw\n",
    "- hmdb51\n",
    "- imagenet-2012\n",
    "- imagenet-sample\n",
    "- kinetics-400\n",
    "- kinetics-600\n",
    "- kinetics-700\n",
    "- kinetics-700-2020\n",
    "- kitti\n",
    "- kitti-multiview\n",
    "- lfw\n",
    "- mnist\n",
    "- open-images-v6\n",
    "- open-images-v7\n",
    "- places\n",
    "- quickstart\n",
    "- quickstart-3d\n",
    "- quickstart-geo\n",
    "- quickstart-groups\n",
    "- quickstart-video\n",
    "- sama-coco\n",
    "- ucf101\n",
    "- voc-2007\n",
    "- voc-2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a Dataset (Example: MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to '/home/paula/fiftyone/mnist/train'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1% |/------------|   664/60000 [100.4ms elapsed, 9.0s remaining, 6.6K samples/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60000/60000 [7.2s elapsed, 0s remaining, 8.2K samples/s]      \n",
      "Downloading split 'test' to '/home/paula/fiftyone/mnist/test'\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [1.2s elapsed, 0s remaining, 8.4K samples/s]         \n",
      "Dataset info written to '/home/paula/fiftyone/mnist/info.json'\n",
      "Loading 'mnist' split 'train'\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60000/60000 [15.8s elapsed, 0s remaining, 3.8K samples/s]      \n",
      "Loading 'mnist' split 'test'\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [2.7s elapsed, 0s remaining, 3.7K samples/s]      \n",
      "Dataset 'mnist' created\n",
      "Name:        mnist\n",
      "Media type:  image\n",
      "Num samples: 70000\n",
      "Persistent:  False\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:               fiftyone.core.fields.ObjectIdField\n",
      "    filepath:         fiftyone.core.fields.StringField\n",
      "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:       fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
      "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n"
     ]
    }
   ],
   "source": [
    "dataset = foz.load_zoo_dataset(\"mnist\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n",
      "\n",
      "Welcome to\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
      "‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ïö‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó     ‚ñà‚ñà‚ïë    ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
      "‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù     ‚ñà‚ñà‚ïë     ‚ïö‚ñà‚ñà‚ïî‚ïù  ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù\n",
      "‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë        ‚ñà‚ñà‚ïë      ‚ñà‚ñà‚ïë   ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë ‚ïö‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n",
      "‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù        ‚ïö‚ïê‚ïù      ‚ïö‚ïê‚ïù    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù v1.3.1\n",
      "\n",
      "If you're finding FiftyOne helpful, here's how you can get involved:\n",
      "\n",
      "|\n",
      "|  ‚≠ê‚≠ê‚≠ê Give the project a star on GitHub ‚≠ê‚≠ê‚≠ê\n",
      "|  https://github.com/voxel51/fiftyone\n",
      "|\n",
      "|  üöÄüöÄüöÄ Join the FiftyOne Discord community üöÄüöÄüöÄ\n",
      "|  https://community.voxel51.com/\n",
      "|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session = fo.launch_app(dataset)\n",
    "# Close the session after you are done exploring\n",
    "# session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://github.com/user-attachments/assets/2d0a82b7-da47-4a1c-8c1a-9db44de28951)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a Specific Split (Example: COCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to '/home/paula/fiftyone/coco-2017/train' if necessary\n",
      "Downloading annotations to '/home/paula/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|    1.9Gb/1.9Gb [1.4m elapsed, 0s remaining, 17.2Mb/s]       \n",
      "Extracting annotations to '/home/paula/fiftyone/coco-2017/raw/instances_train2017.json'\n",
      "Downloading images to '/home/paula/fiftyone/coco-2017/tmp-download/train2017.zip'\n",
      "   1% ||---|    1.3Gb/144.1Gb [1.0m elapsed, 1.8h remaining, 18.6Mb/s]    \n",
      "coco-2017 dataset is not available, please install it if needed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    coco_train = foz.load_zoo_dataset(\"coco-2017\", split=\"train\")\n",
    "    print(coco_train)\n",
    "except:\n",
    "    print(\"coco-2017 dataset is not available, please install it if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and Loading a Dataset with Specific Splits and Downsampling (Example: open-images-v6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to '/home/paula/fiftyone/open-images-v6/train' if necessary\n",
      "Downloading 'https://storage.googleapis.com/openimages/2018_04/train/train-images-boxable-with-rotation.csv' to '/home/paula/fiftyone/open-images-v6/train/metadata/image_ids.csv'\n",
      "  22% |‚ñà|----|    1.0Gb/4.8Gb [4.9s elapsed, 17.9s remaining, 198.7Mb/s]    \n",
      "open-images-v6 dataset is not available, please install it if needed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dataset = foz.load_zoo_dataset(\n",
    "        \"open-images-v6\",\n",
    "        splits=[\"train\", \"validation\"],\n",
    "        label_types=[\"detections\", \"segmentations\"],\n",
    "        classes=[\"Car\", \"Person\"],\n",
    "        max_samples=50,\n",
    "    )\n",
    "    print(dataset)\n",
    "except:\n",
    "    print(\"open-images-v6 dataset is not available, please install it if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Dataset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco-2017 metadata is not available, please install it if needed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    metadata = foz.get_zoo_dataset_info(\"coco-2017\")\n",
    "    print(metadata)\n",
    "except:\n",
    "    print(\"coco-2017 metadata is not available, please install it if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Loading a Remote Image Dataset\n",
    "\n",
    "With fiftyOne you can work/create zoo datasets whose download/preparation methods are hosted via GitHub repositories or public URLs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/voxel51/coco-2017...\n",
      "   33.7Kb [1.4ms elapsed, ? remaining, 350.4Mb/s]  \n",
      "Downloading split 'validation' to '/home/paula/fiftyone/voxel51/coco-2017/validation' if necessary\n",
      "Downloading annotations to '/home/paula/fiftyone/voxel51/coco-2017/tmp-download/annotations_trainval2017.zip'\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|    1.9Gb/1.9Gb [1.4m elapsed, 0s remaining, 20.7Mb/s]       \n",
      "Extracting annotations to '/home/paula/fiftyone/voxel51/coco-2017/raw/instances_val2017.json'\n",
      "Downloading images to '/home/paula/fiftyone/voxel51/coco-2017/tmp-download/val2017.zip'\n",
      "  20% |‚ñà-----|    1.2Gb/6.1Gb [1.0m elapsed, 4.0m remaining, 22.8Mb/s]    "
     ]
    }
   ],
   "source": [
    "dataset = foz.load_zoo_dataset(\n",
    "    \"https://github.com/voxel51/coco-2017\",\n",
    "    split=\"validation\",\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset, port=5152, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other loading examples with remote datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load 50 random samples from the validation split\n",
    "\n",
    "Only the required images will be downloaded (if necessary).\n",
    "By default, only detections are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = foz.load_zoo_dataset(\n",
    "    \"https://github.com/voxel51/coco-2017\",\n",
    "    split=\"validation\",\n",
    "    max_samples=50,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset, port=5152, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load segmentations for 25 samples from the validation split that contain cats and dogs\n",
    "\n",
    "Images that contain all `classes` will be prioritized first, followed by images that contain at least one of the required `classes`. If there are not enough images matching `classes` in the split to meet `max_samples`, only the available images will be loaded. Images will only be downloaded if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = foz.load_zoo_dataset(\n",
    "    \"https://github.com/voxel51/coco-2017\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"segmentations\"],\n",
    "    classes=[\"cat\", \"dog\"],\n",
    "    max_samples=25,\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset, port=5152, auto=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the entire validation split and load both detections and segmentations. \n",
    "\n",
    "Subsequent partial loads of the validation split will never require downloading any images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"https://github.com/voxel51/coco-2017\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"detections\", \"segmentations\"],\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset, port=5152, auto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fiftyone as fo\n",
    "\n",
    "dataset = fo.Dataset.from_images_dir(\n",
    "    dataset_dir=\"[https://your-remote-server.com/images](https://www.google.com/search?q=https://your-remote-server.com/images)\",\n",
    "    name=\"remote-images\",\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset)\n",
    "# session.close()\n",
    "\n",
    "\n",
    "\n",
    "import fiftyone as fo\n",
    "\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=\"[https://your-remote-server.com/coco-dataset](https://www.google.com/search?q=https://your-remote-server.com/coco-dataset)\",\n",
    "    dataset_type=fo.types.COCODetectionDataset,\n",
    "    name=\"remote-coco\",\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset)\n",
    "# session.close()\n",
    "\n",
    "\n",
    "import fiftyone as fo\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "class RemoteResNet(fo.core.models.TorchModel):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.model = None\n",
    "\n",
    "    def _load_model(self, filepath):\n",
    "        self.model = models.resnet50()\n",
    "        self.model.load_state_dict(torch.hub.load_state_dict_from_url(filepath))\n",
    "        self.model.eval()\n",
    "\n",
    "    def _predict(self, sample):\n",
    "        # Implement your prediction logic here using self.model\n",
    "        # ...\n",
    "        pass\n",
    "\n",
    "def load_remote_resnet():\n",
    "    model_url = \"[https://your-remote-server.com/resnet50.pth](https://www.google.com/search?q=https://your-remote-server.com/resnet50.pth)\"\n",
    "    model = RemoteResNet(model_path=model_url)\n",
    "    return model\n",
    "\n",
    "remote_resnet = load_remote_resnet()\n",
    "\n",
    "# Then the model can be used with apply_model()\n",
    "# dataset.apply_model(remote_resnet, label_field=\"remote_predictions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "FiftyOne Zoo simplifies the process of working with computer vision datasets and models. It provides a valuable resource for researchers, developers, and enthusiasts.\n",
    "\n",
    "### Further Exploration:\n",
    "* Explore the [FiftyOne documentation](https://docs.voxel51.com/) for more advanced features.\n",
    "* Try different datasets and models from the Zoo.\n",
    "* Integrate FiftyOne Zoo into your computer vision workflows.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "To continue exploring, check out:\n",
    "- [Getting Started with FiftyOne](https://beta-docs.voxel51.com/getting_started/)\n",
    "- [Other Datasets](https://beta-docs.voxel51.com/data/dataset_zoo/)\n",
    "- [Other Models](https://beta-docs.voxel51.com/models/model_zoo/)\n",
    "- Join our [Discord community](https://community.voxel51.com)\n",
    "- Follow us on [LinkedIn](https://www.linkedin.com/company/voxel51/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GT_Exp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
