{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYeuCwo6sEJ4"
      },
      "source": [
        "# 1. MNIST Dataset Exploration with FiftyOne\n",
        "\n",
        "Welcome to the first notebook in our series on image classification with FiftyOne and PyTorch!\n",
        "\n",
        "In this step, we will load the classic MNIST dataset from the FiftyOne Dataset Zoo, explore its structure, and compute and visualize its metadata. This initial exploration is crucial for understanding the data we'll be working with in the subsequent steps.\n",
        "\n",
        "**Key concepts covered:**\n",
        "*   Loading datasets from the FiftyOne Dataset Zoo\n",
        "*   Computing image metadata (size, width, height)\n",
        "*   Using FiftyOne aggregations for data statistics\n",
        "*   Visualizing dataset distributions in the FiftyOne App"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RH82hd-sEJ5"
      },
      "source": [
        "## Installation\n",
        "\n",
        "First, let's install the required packages. These are the Python packages that we will use for the whole series of notebooks. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Th95Bxv2sEJ6"
      },
      "outputs": [],
      "source": [
        "# Remove > /dev/null if you encounter errors after installation, we have it just to keep the notebook clean.\n",
        "!pip install fiftyone torch torchvision numpy albumentations umap-learn ipykernel jupyter > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPk9r4QVsEJ7"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ckTja2wvsEJ7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set environment variables for reproducibility BEFORE importing torch\n",
        "os.environ['PYTHONHASHSEED'] = '51'\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as Fun\n",
        "import torchvision.transforms.v2 as transforms\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "import fiftyone.brain as fob\n",
        "from torch.utils.data import Dataset, ConcatDataset\n",
        "from fiftyone import ViewField as F\n",
        "import fiftyone.utils.random as four\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import random\n",
        "from typing import Optional, Dict, Tuple, Any"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ml7WeDzsEJ7"
      },
      "source": [
        "### Loading the MNIST Dataset from FiftyOne's Dataset Zoo\n",
        "\n",
        "A FiftyOne dataset wraps together annotations and image data into a unified, queryable structure. Unlike traditional approaches where you manage separate files for images and labels, FiftyOne treats each sample as a rich object containing the image, ground truth labels, metadata, and any predictions or embeddings you add later.\n",
        "\n",
        "Loading MNIST from the [FiftyOne Dataset Zoo](https://docs.voxel51.com/dataset_zoo/index.html) is straightforward. We'll start by loading the test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lyVwmsIsEJ8",
        "outputId": "d0ee1018-40a8-47c8-ed99-59e084efdb57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading split 'test' to '/root/fiftyone/mnist/test'\n",
            "   3% |/------------|   316/10000 [100.4ms elapsed, 3.1s remaining, 3.1K samples/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████| 10000/10000 [3.2s elapsed, 0s remaining, 3.2K samples/s]      \n",
            "Dataset info written to '/root/fiftyone/mnist/info.json'\n",
            "Loading 'mnist' split 'test'\n",
            " 100% |█████████████| 10000/10000 [5.3s elapsed, 0s remaining, 2.1K samples/s]      \n",
            "Dataset 'mnist-test-set' created\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Name:        mnist-test-set\n",
              "Media type:  image\n",
              "Num samples: 10000\n",
              "Persistent:  True\n",
              "Tags:        []\n",
              "Sample fields:\n",
              "    id:               fiftyone.core.fields.ObjectIdField\n",
              "    filepath:         fiftyone.core.fields.StringField\n",
              "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
              "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
              "    created_at:       fiftyone.core.fields.DateTimeField\n",
              "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
              "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We will load the test split from the dataset first. \n",
        "# We set persistent=True on the dataset to keep our changes through different Python sessions.\n",
        "test_dataset = foz.load_zoo_dataset(\"mnist\", split='test', dataset_name=\"mnist-test-set\", persistent=True)\n",
        "test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7h4vKOrsEJ8"
      },
      "source": [
        "Let's launch the FiftyOne App to visualize the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "xC_sQ0YusEJ8",
        "outputId": "594c1a36-4afc-4d94-fb8d-756d2326cbdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to FiftyOne on port 5151 at 0.0.0.0.\n",
            "If you are not connecting to a remote session, you may need to start a new session and specify a port\n",
            "Session launched. Run `session.show()` to open the App in a cell output.\n",
            "http://0.0.0.0:5151/\n"
          ]
        }
      ],
      "source": [
        "session = fo.launch_app(test_dataset, auto=False)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/andandandand/fiftyone/blob/develop/docs/source/getting_started_experiences/Classification/assets/MNIST-vis.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4y1pzs5sEJ8"
      },
      "source": [
        "With `compute_metadata()`, we can easily add metadata like image size, width, height, and number of channels to each sample in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvYAWu--sEJ8",
        "outputId": "ebbe361c-1862-487c-e531-cb2116abbb70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing metadata...\n",
            " 100% |█████████████| 10000/10000 [5.9s elapsed, 0s remaining, 1.6K samples/s]        \n"
          ]
        }
      ],
      "source": [
        "test_dataset.compute_metadata()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Nstk1osEJ8"
      },
      "source": [
        "We can perform [aggregations](https://docs.voxel51.com/user_guide/using_aggregations.html) on the dataset to explore the metadata. For example, we can find the range, mean, and standard deviation of the image sizes in bytes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSQRZjSasEJ9",
        "outputId": "0da9f3d9-9241-4026-82fb-b818716c7960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File size (bytes) range: (483, 1033)\n",
            "File size (bytes) mean: 768.61\n",
            "File size (bytes) std dev: 84.01\n"
          ]
        }
      ],
      "source": [
        "print(f'File size (bytes) range: {test_dataset.bounds(\"metadata.size_bytes\")}')\n",
        "print(f'File size (bytes) mean: {test_dataset.mean(\"metadata.size_bytes\"):.2f}')\n",
        "print(f'File size (bytes) std dev: {test_dataset.std(\"metadata.size_bytes\"):.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M879kIdisEJ9"
      },
      "source": [
        "### Visualizing the Ground Truth Label Distribution\n",
        "\n",
        "In the FiftyOne App, you can visualize the distributions of any field. This is useful for checking class balance or understanding metadata distributions.\n",
        "\n",
        "1. Click the `+` symbol next to the `Samples` tab.\n",
        "2. Select `Histograms`.\n",
        "3. Choose `ground_truth.label` from the dropdown to see the class distribution.\n",
        "4. Press `Split horizontally` to see the MNST images alongside their class distribution.\n",
        "\n",
        "You should see that the classes are overall balanced, which simplifies training and evaluation. There is only a slight dominance of 1s in the distribution. \n",
        "\n",
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/ground_truh_distribution_mnist.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "52-tYT0gsEJ9"
      },
      "outputs": [],
      "source": [
        "session.refresh()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise\n",
        "\n",
        "* Repeat the histogram visualization process on `metadata.size_bytes` and select the field from the METADATA navigation bar. You should be able to produce a visualization with the `size_bytes` distribution like the one shown below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/andandandand/fiftyone/blob/develop/docs/source/getting_started_experiences/Classification/assets/MNIST_size_byes.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Y8zxTksEJ9"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "Now that we have explored the basic properties of the MNIST dataset, we are ready for the next step: creating image embeddings with CLIP to understand the semantic relationships between images.\n",
        "\n",
        "Proceed to `step_2_clip_embeddings.ipynb`."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
