{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYeuCwo6sEJ4"
      },
      "source": [
        "# 1. MNIST Dataset Exploration with FiftyOne\n",
        "\n",
        "Welcome to the first notebook in our series on image classification with FiftyOne. In this series we will explore foundational ideas on image classification, image embeddings, and model comparison.\n",
        "\n",
        "![](https://github.com/andandandand/fiftyone/blob/develop/docs/source/getting_started_experiences/Classification/assets/mnist_clean.webp?raw=1)\n",
        "\n",
        "In this first step, we will load the classic [MNIST dataset](https://docs.voxel51.com/dataset_zoo/datasets.html#dataset-zoo-mnist) from the [FiftyOne Dataset Zoo](https://docs.voxel51.com/dataset_zoo/datasets.html), explore its structure, and compute and visualize its metadata. This initial exploration is important for understanding the data we'll be working with in the next steps. It will also help you gain familiarity with the FiftyOne app and SDK. \n",
        "\n",
        "**Key concepts covered:**\n",
        "*   Loading datasets from the FiftyOne Dataset Zoo\n",
        "*   Computing image metadata (size, width, height)\n",
        "*   Using FiftyOne aggregations for data statistics\n",
        "*   Visualizing dataset distributions in the FiftyOne App"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RH82hd-sEJ5"
      },
      "source": [
        "## Installation\n",
        "\n",
        "First, let's install the required packages. These are the Python packages that we will use for the whole series of notebooks. The [requirements.txt]() file has the exact set of versions that I have used to make the environment run. \n",
        "\n",
        "Remember to create a virtual environment with \n",
        "\n",
        "```bash\n",
        "python -m venv .venv \n",
        "```\n",
        "and to activate it with\n",
        "\n",
        "```bash\n",
        "source .venv/bin/activate\n",
        "```\n",
        "This environment must be selected as the interpreter for this notebook.\n",
        "\n",
        "These notebooks werre tested on a Runpod.io PyTorch 2.1 environment with 1X RTX 2000 Ada and 6 vCPU with 31 GB RAM. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Th95Bxv2sEJ6"
      },
      "outputs": [],
      "source": [
        "# Remove > /dev/null if you encounter errors after installation, we have it just to keep the notebook clean.\n",
        "!pip install -r requirements.txt > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPk9r4QVsEJ7"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ckTja2wvsEJ7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set environment variables for reproducibility BEFORE importing torch\n",
        "os.environ['PYTHONHASHSEED'] = '51'\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as Fun\n",
        "import torchvision.transforms.v2 as transforms\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "import fiftyone.brain as fob\n",
        "from torch.utils.data import Dataset, ConcatDataset\n",
        "from fiftyone import ViewField as F\n",
        "import fiftyone.utils.random as four\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import random\n",
        "from typing import Optional, Dict, Tuple, Any"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ml7WeDzsEJ7"
      },
      "source": [
        "### Loading the MNIST Dataset from FiftyOne's Dataset Zoo\n",
        "\n",
        "A FiftyOne dataset wraps together annotations and image data into a unified, queryable structure. Unlike traditional approaches where you manage separate files for images and labels, FiftyOne treats each sample as a rich object containing the image, ground truth labels, metadata, and any predictions or embeddings you add later.\n",
        "\n",
        "Loading MNIST from the [FiftyOne Dataset Zoo](https://docs.voxel51.com/dataset_zoo/index.html) is straightforward. We'll start by loading the test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lyVwmsIsEJ8",
        "outputId": "d0ee1018-40a8-47c8-ed99-59e084efdb57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading split 'test' to '/root/fiftyone/mnist/test'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:01<00:00, 6.99MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 220kB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 2.13MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 1.96MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   3% |/------------|   295/10000 [101.3ms elapsed, 3.3s remaining, 2.9K samples/s] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [3.3s elapsed, 0s remaining, 3.0K samples/s]      \n",
            "Dataset info written to '/root/fiftyone/mnist/info.json'\n",
            "Loading 'mnist' split 'test'\n",
            " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [5.1s elapsed, 0s remaining, 2.1K samples/s]      \n",
            "Dataset 'mnist-test-set' created\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Name:        mnist-test-set\n",
              "Media type:  image\n",
              "Num samples: 10000\n",
              "Persistent:  True\n",
              "Tags:        []\n",
              "Sample fields:\n",
              "    id:               fiftyone.core.fields.ObjectIdField\n",
              "    filepath:         fiftyone.core.fields.StringField\n",
              "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
              "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
              "    created_at:       fiftyone.core.fields.DateTimeField\n",
              "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
              "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We will load the test split from the dataset first. \n",
        "# We set persistent=True on the dataset to keep our changes through different Python sessions.\n",
        "test_dataset = foz.load_zoo_dataset(\"mnist\", split='test', dataset_name=\"mnist-test-set\", persistent=True)\n",
        "test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7h4vKOrsEJ8"
      },
      "source": [
        "Let's launch the FiftyOne App to visualize the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "xC_sQ0YusEJ8",
        "outputId": "594c1a36-4afc-4d94-fb8d-756d2326cbdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Session launched. Run `session.show()` to open the App in a cell output.\n",
            "\n",
            "Welcome to\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
            "â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ•‘    â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
            "â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•     â–ˆâ–ˆâ•‘     â•šâ–ˆâ–ˆâ•”â•  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•\n",
            "â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘        â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•‘   â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—\n",
            "â•šâ•â•     â•šâ•â•â•šâ•â•        â•šâ•â•      â•šâ•â•    â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•â•â•šâ•â•â•â•â•â•â• v1.7.0\n",
            "\n",
            "If you're finding FiftyOne helpful, here's how you can get involved:\n",
            "\n",
            "|\n",
            "|  â­â­â­ Give the project a star on GitHub â­â­â­\n",
            "|  https://github.com/voxel51/fiftyone\n",
            "|\n",
            "|  ðŸš€ðŸš€ðŸš€ Join the FiftyOne Discord community ðŸš€ðŸš€ðŸš€\n",
            "|  https://community.voxel51.com/\n",
            "|\n",
            "\n",
            "http://0.0.0.0:5151/\n"
          ]
        }
      ],
      "source": [
        "session = fo.launch_app(test_dataset, auto=False)\n",
        "print(session.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/andandandand/fiftyone/blob/develop/docs/source/getting_started_experiences/Classification/assets/MNIST-vis.webp?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4y1pzs5sEJ8"
      },
      "source": [
        "With `compute_metadata()`, we can easily add metadata like image size, width, height, and number of channels to each sample in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvYAWu--sEJ8",
        "outputId": "ebbe361c-1862-487c-e531-cb2116abbb70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing metadata...\n",
            " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [6.1s elapsed, 0s remaining, 1.9K samples/s]      \n"
          ]
        }
      ],
      "source": [
        "test_dataset.compute_metadata()\n",
        "# Refresh the session to ensure the dataset view in the app is updated\n",
        "session.refresh()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This metadata is wrapped together with our samples and we can inspect it through the FiftyOne app. We can click on the `JSON` icon `{}` to retrieve it when we need it. \n",
        "\n",
        "![](https://github.com/andandandand/fiftyone/blob/develop/docs/source/getting_started_experiences/Classification/assets/mnist_five.webp?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The only field in the samples of the dataset that is mandatory is the local `filepath`. All other annotations and tags are optional for the FiftyOne dataset. The `id` field is a hash that is automatically generated for each sample and allows us to identify each data point uniquely (even if we had duplicate images in the dataset). The dataset for MNIST that we have downloaded from the FiftyOne dataset zoo has come prepared in this format. \n",
        "FiftyOne is a \"logical database\" that connects our media files (images, video, geolocation data, etc.) with all its annotations and metadata. MongoDB is the default database backend. \n",
        "\n",
        "![](https://github.com/andandandand/fiftyone/blob/develop/docs/source/getting_started_experiences/Classification/assets/five_json.webp?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the `JSON` window, we can copy any field, here I take the filepath to open the image within my notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+vQpfhfHos6J4r8V6Ro4eISrHGWuZipzghFAyOOuea4/V7bSLW48vSdSur+MHBkmsxAD7gb2J/HFZtOUBmAZgoJwWI6V6fr+u/DzUBpenXR17UBptitkupW5SMSAZIYRuNxALEYJHArl9X8IxRabLrHh/Uk1jSY2AldYzHPbZ6ebGc7QSCAwJBx2ziuWp8SebKke5U3MF3OcAZ7n2rt7/AOE3iiC9ljsLaHUbNSNl9BcxCJwQOcl+Pxxxz0rR8N2P/CudUOta1rGntsidDpNndrPJdMVIEcgTKqmepJ7cDpXmlFFFFf/Z",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABkklEQVR4AcVQPU8CQRCd3bvD1ihnZUFBNLEzRjutTGwlWlkbaCwsLPwHNlqjvZVBY2dnsMOAFoQLWhhLgxqDhR/A7Y4zcwtB/4AvBzs7b97MmwVw0KCBPsVXH5Kzz9FVQ0CU8jxipGaIk5DUrFKk/Q2P05o7K49n/MHsXmStuT6e5qnDKBzUqtiL4+IKi5KZg8kWP+4q9fYpglJgh2UUl+Jb+ne7uEPuVAsTjy+TYoNMcVJAB9lMAeya+SQmM47zrUKT6nbBVzrbG4kjC0YhKkykvDC9TviAsfnG0iplaU/qRifXaLBheeamXoHNMIMLjY7TCa/BX8QT8MhYuHWJ0eARxDW55YX5wVOQr7bmnCPeWQo82YH58aiV45EMquJF+eewVHvellCLwO/bo1JqMdrsMaktAiqIwfgQACJY3yC8X8kqxJPUc60DmQFqqhVJW+Y42NmgiEGazPlnVmK2AirImSJdqWyskL94auREkGQU5LDzenhUPkU08f1+WnTc1Mq3vB6vpaN24+0Mml+c+Sf8AOevdTQW/76JAAAAAElFTkSuQmCC",
            "text/plain": [
              "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=28x28>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image = Image.open(\"/root/fiftyone/mnist/test/data/000016.jpg\")\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Nstk1osEJ8"
      },
      "source": [
        "We can perform [aggregations](https://docs.voxel51.com/user_guide/using_aggregations.html) on the dataset to explore the metadata. For example, we can find the range, mean, and standard deviation of the image sizes in bytes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSQRZjSasEJ9",
        "outputId": "0da9f3d9-9241-4026-82fb-b818716c7960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File size (bytes) range: (483, 1033)\n",
            "File size (bytes) mean: 768.61\n",
            "File size (bytes) std dev: 84.01\n"
          ]
        }
      ],
      "source": [
        "print(f'File size (bytes) range: {test_dataset.bounds(\"metadata.size_bytes\")}')\n",
        "print(f'File size (bytes) mean: {test_dataset.mean(\"metadata.size_bytes\"):.2f}')\n",
        "print(f'File size (bytes) std dev: {test_dataset.std(\"metadata.size_bytes\"):.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M879kIdisEJ9"
      },
      "source": [
        "### Visualizing the Ground Truth Label Distribution\n",
        "\n",
        "In the FiftyOne App, you can visualize the distributions of any field. This is useful for checking class balance or understanding metadata distributions.\n",
        "\n",
        "1. Click the `+` symbol next to the `Samples` tab.\n",
        "2. Select `Histograms`.\n",
        "3. Choose `ground_truth.label` from the dropdown to see the class distribution.\n",
        "4. Press `Split horizontally` to see the MNST images alongside their class distribution.\n",
        "\n",
        "You should see that the classes are overall balanced, which simplifies training and evaluation. There is only a slight dominance of 1s in the distribution. \n",
        "\n",
        "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/ground_truh_distribution_mnist.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "52-tYT0gsEJ9"
      },
      "outputs": [],
      "source": [
        "session.refresh()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise\n",
        "\n",
        "* Repeat the histogram visualization process on `metadata.size_bytes` and select the field from the METADATA navigation bar. You should be able to produce a visualization with the `size_bytes` distribution like the one shown below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://github.com/andandandand/fiftyone/blob/develop/docs/source/getting_started_experiences/Classification/assets/MNIST_size_byes.webp?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_Y8zxTksEJ9"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "Now that we have explored the basic properties of the MNIST dataset, we are ready for the next step: creating image embeddings with CLIP to understand the semantic relationships between images.\n",
        "\n",
        "Proceed to `step_2_clip_embeddings.ipynb`."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
