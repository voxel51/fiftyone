{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MNIST Dataset Exploration with FiftyOne\n",
    "\n",
    "Welcome to the first notebook in our series on image classification with FiftyOne and PyTorch!\n",
    "\n",
    "In this step, we will load the classic MNIST dataset from the FiftyOne Dataset Zoo, explore its structure, and compute and visualize its metadata. This initial exploration is crucial for understanding the data we'll be working with in the subsequent steps.\n",
    "\n",
    "**Key concepts covered:**\n",
    "*   Loading datasets from the FiftyOne Dataset Zoo\n",
    "*   Computing image metadata (size, width, height)\n",
    "*   Using FiftyOne aggregations for data statistics\n",
    "*   Visualizing dataset distributions in the FiftyOne App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, let's install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove > /dev/null if you encounter errors during installation\n",
    "!pip install fiftyone==1.5.2 torch torchvision numpy albumentations > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FiftyOne Plug-ins\n",
    "\n",
    "We'll also install FiftyOne plugins for model evaluation and data augmentation, which we will use in later notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plug-in to evaluate the performance of our classification models\n",
    "!fiftyone plugins download \\\n",
    "    https://github.com/voxel51/fiftyone-plugins \\\n",
    "    --plugin-names @voxel51/evaluation\n",
    "\n",
    "# Plug-in for image augmentations\n",
    "!fiftyone plugins download https://github.com/jacobmarks/fiftyone-albumentations-plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables for reproducibility BEFORE importing torch\n",
    "os.environ['PYTHONHASHSEED'] = '51'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.brain as fob\n",
    "from torch.utils.data import Dataset, ConcatDataset\n",
    "from fiftyone import ViewField as F\n",
    "import fiftyone.utils.random as four\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import random\n",
    "from typing import Optional, Dict, Tuple, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the MNIST Dataset from FiftyOne's Dataset Zoo\n",
    "\n",
    "A FiftyOne dataset wraps together annotations and image data into a unified, queryable structure. Unlike traditional approaches where you manage separate files for images and labels, FiftyOne treats each sample as a rich object containing the image, ground truth labels, metadata, and any predictions or embeddings you add later.\n",
    "\n",
    "Loading MNIST from the [FiftyOne Dataset Zoo](https://docs.voxel51.com/dataset_zoo/index.html) is straightforward. We'll start by loading the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will load the test split from the dataset first\n",
    "test_dataset = foz.load_zoo_dataset(\"mnist\", split='test', dataset_name=\"mnist-test-set\", persistent=True)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's launch the FiftyOne App to visualize the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(test_dataset, auto=False)\n",
    "print(session.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `compute_metadata()`, we can easily add metadata like image size, width, height, and number of channels to each sample in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.compute_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform [aggregations](https://docs.voxel51.com/user_guide/using_aggregations.html) on the dataset to explore its properties. For example, we can find the range, mean, and standard deviation of the image sizes in bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'File size (bytes) range: {test_dataset.bounds(\"metadata.size_bytes\")}')\n",
    "print(f'File size (bytes) mean: {test_dataset.mean(\"metadata.size_bytes\"):.2f}')\n",
    "print(f'File size (bytes) std dev: {test_dataset.std(\"metadata.size_bytes\"):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Distributions\n",
    "\n",
    "In the FiftyOne App, you can visualize the distributions of any field. This is useful for checking class balance or understanding metadata distributions.\n",
    "\n",
    "1. Click the `+` symbol next to the `Samples` tab.\n",
    "2. Select `Histograms`.\n",
    "3. Choose `ground_truth.label` from the dropdown to see the class distribution.\n",
    "4. Add another histogram for `metadata.size_bytes`.\n",
    "\n",
    "You should see that the classes are well-balanced, which is great for training and evaluation.\n",
    "\n",
    "![](https://github.com/andandandand/practical-computer-vision/blob/main/images/ground_truh_distribution_mnist.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that we have explored the basic properties of the MNIST dataset, we are ready for the next step: creating image embeddings with CLIP to understand the semantic relationships between images.\n",
    "\n",
    "Proceed to `2_clip_embeddings.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}