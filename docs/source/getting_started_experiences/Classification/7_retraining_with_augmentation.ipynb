{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data Augmentation, Retraining, and Saving / Sharing our Work\n",
    "\n",
    "In this final notebook, we'll use the insights gained from our analysis to improve our model. We will identify challenging samples from the training set—those that were misclassified, are highly unique, or had low prediction confidence. We will then apply targeted **data augmentation** to these samples and fine-tune our LeNet model on this enriched dataset.\n",
    "\n",
    "**Key concepts covered:**\n",
    "*   Identifying problematic samples for augmentation\n",
    "*   Defining effective data augmentation strategies for MNIST\n",
    "*   Creating a combined dataset of original and augmented data\n",
    "*   Fine-tuning a pre-trained model\n",
    "*   Comparing performance before and after fine-tuning\n",
    "*   Saving our work on the local hard drive\n",
    "*   [Pushing our curated datasets to HuggingFace Hub](https://docs.voxel51.com/integrations/huggingface.html#pushing-datasets-to-the-hub) with FiftyOne format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Let's begin by setting up our environment, including all necessary imports and helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fun\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torch.utils.data import Dataset, ConcatDataset\n",
    "from torch.optim import Adam\n",
    "\n",
    "import fiftyone as fo\n",
    "from fiftyone import ViewField as F\n",
    "import albumentations as A\n",
    "\n",
    "# Redefine model and dataset classes\n",
    "class ModernLeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModernLeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(16, 120, kernel_size=4)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(Fun.relu(self.conv1(x)))\n",
    "        x = self.pool(Fun.relu(self.conv2(x)))\n",
    "        x = Fun.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = Fun.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def create_deterministic_training_dataloader(dataset, batch_size, shuffle=True, **kwargs):\n",
    "    generator = torch.Generator().manual_seed(51)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, generator=generator if shuffle else None, **kwargs)\n",
    "\n",
    "def set_seeds(seed=51):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Samples for Augmentation\n",
    "\n",
    "First, we need to get our model's predictions on the training set to identify which samples it misclassified. We'll need to run inference on the training set, similar to how we did for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting train preds: 100%|██████████| 797/797 [00:16<00:00, 48.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 469 misclassified training samples.\n"
     ]
    }
   ],
   "source": [
    "# Load datasets and model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_dataset = fo.load_dataset(\"mnist-training-set\")\n",
    "test_dataset = fo.load_dataset(\"mnist-test-set\")\n",
    "model_save_path = Path(os.getcwd()) / 'best_lenet.pth'\n",
    "loaded_model = ModernLeNet5().to(device)\n",
    "loaded_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "\n",
    "# Recreate transforms and dataloaders\n",
    "mean_intensity, std_intensity = 0.1307, 0.3081 # Pre-computed\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.ToImage(), transforms.ToDtype(torch.float32, scale=True),\n",
    "    transforms.Normalize((mean_intensity,), (std_intensity,))\n",
    "])\n",
    "dataset_classes = sorted(train_dataset.distinct(\"ground_truth.label\"))\n",
    "label_map = {label: i for i, label in enumerate(dataset_classes)}\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "class CustomTorchImageDataset(Dataset):\n",
    "    def __init__(self, fo_dset, xforms, l_map):\n",
    "        self.fo_dset, self.xforms, self.l_map = fo_dset, xforms, l_map\n",
    "        self.img_paths = self.fo_dset.values(\"filepath\")\n",
    "        self.labels = self.fo_dset.values(\"ground_truth.label\")\n",
    "    def __len__(self): return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.img_paths[idx]).convert('L')\n",
    "        label = self.l_map[self.labels[idx]]\n",
    "        return self.xforms(img), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "torch_train_set = CustomTorchImageDataset(train_dataset, image_transforms, label_map)\n",
    "train_inference_loader = torch.utils.data.DataLoader(torch_train_set, batch_size=64, shuffle=False)\n",
    "\n",
    "# Add predictions to training set if they don't exist\n",
    "if \"lenet_train_classification\" not in train_dataset.get_field_schema():\n",
    "    train_preds, train_logits = [], []\n",
    "    with torch.inference_mode():\n",
    "        for imgs, _ in tqdm(train_inference_loader, desc=\"Getting train preds\"):\n",
    "            logits = loaded_model(imgs.to(device))\n",
    "            train_logits.append(logits.cpu().numpy())\n",
    "            train_preds.extend(torch.max(logits, 1)[1].cpu().numpy())\n",
    "    train_logits = np.concatenate(train_logits)\n",
    "    \n",
    "    classifications = []\n",
    "    for i in range(len(train_dataset)):\n",
    "        pred_idx = train_preds[i]\n",
    "        logits = train_logits[i]\n",
    "        conf = float(Fun.softmax(torch.tensor(logits), dim=0)[pred_idx])\n",
    "        classifications.append(fo.Classification(label=dataset_classes[pred_idx], confidence=conf, logits=logits.tolist()))\n",
    "    train_dataset.set_values(\"lenet_train_classification\", classifications)\n",
    "    train_dataset.save()\n",
    "\n",
    "# Create view of misclassified training samples\n",
    "mislabeled_train_images_view = train_dataset.match(F(\"lenet_train_classification.label\") != F(\"ground_truth.label\"))\n",
    "print(f\"Found {len(mislabeled_train_images_view)} misclassified training samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Augmentations\n",
    "\n",
    "Effective augmentation for MNIST involves creating realistic variations that a model might encounter. We'll use small geometric transformations (rotation, translation, scaling) and elastic deformations to simulate natural handwriting styles. We will use the `albumentations` library for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds(51)\n",
    "mnist_augmentations = A.Compose([\n",
    "    A.Affine(\n",
    "        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "        scale=(0.9, 1.1),\n",
    "        rotate=(-10, 10),\n",
    "        p=0.8\n",
    "    ),\n",
    "    A.ElasticTransform(\n",
    "        alpha=20, sigma=5, border_mode=cv2.BORDER_CONSTANT, p=0.6\n",
    "    ),\n",
    "    A.GridDistortion(num_steps=3, distort_limit=0.1, p=0.3),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Augmented Dataset\n",
    "\n",
    "We'll define a new PyTorch `Dataset` class that takes our misclassified samples and applies these augmentations on the fly. For each misclassified sample, it will generate multiple augmented versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedMNISTDataset(Dataset):\n",
    "    def __init__(self, fiftyone_view, label_map, base_transforms, augmentations, augment_factor=5):\n",
    "        self.image_paths = fiftyone_view.values(\"filepath\")\n",
    "        self.str_labels = fiftyone_view.values(\"ground_truth.label\")\n",
    "        self.label_map = label_map\n",
    "        self.base_transforms = base_transforms\n",
    "        self.augmentations = augmentations\n",
    "        self.augment_factor = augment_factor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths) * self.augment_factor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        base_idx = idx // self.augment_factor\n",
    "        image = Image.open(self.image_paths[base_idx]).convert('L')\n",
    "        image_np = np.array(image, dtype=np.uint8)\n",
    "        augmented = self.augmentations(image=image_np)['image']\n",
    "        image = Image.fromarray(augmented).convert(\"L\")\n",
    "        if self.base_transforms: image = self.base_transforms(image)\n",
    "        label_idx = self.label_map.get(self.str_labels[base_idx], -1)\n",
    "        return image, torch.tensor(label_idx, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size: 51000\n",
      "Augmented samples added: 4690\n",
      "Combined dataset size: 55690\n"
     ]
    }
   ],
   "source": [
    "torch_augmented_dataset = AugmentedMNISTDataset(\n",
    "    mislabeled_train_images_view,\n",
    "    label_map=label_map,\n",
    "    base_transforms=image_transforms,\n",
    "    augmentations=mnist_augmentations,\n",
    "    augment_factor=10\n",
    ")\n",
    "\n",
    "# Combine original training set with the new augmented samples\n",
    "combined_dataset = ConcatDataset([torch_train_set, torch_augmented_dataset])\n",
    "print(f\"Original training set size: {len(torch_train_set)}\")\n",
    "print(f\"Augmented samples added: {len(torch_augmented_dataset)}\")\n",
    "print(f\"Combined dataset size: {len(combined_dataset)}\")\n",
    "\n",
    "# Create a new DataLoader for fine-tuning\n",
    "combined_train_loader = create_deterministic_training_dataloader(\n",
    "    combined_dataset, batch_size=64, shuffle=True, num_workers=os.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning the Model\n",
    "\n",
    "We'll now fine-tune our model. We start with the best weights from our initial training and train for a few more epochs on the combined dataset. We use a **lower learning rate** for fine-tuning to make small, careful adjustments to the already-learned weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 1:   0%|          | 0/871 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 1: 100%|██████████| 871/871 [00:12<00:00, 71.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Validation Loss: 0.0404\n",
      "Saved improved retrained model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 2: 100%|██████████| 871/871 [00:12<00:00, 70.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Validation Loss: 0.0390\n",
      "Saved improved retrained model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 3: 100%|██████████| 871/871 [00:12<00:00, 67.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Validation Loss: 0.0393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 4: 100%|██████████| 871/871 [00:11<00:00, 76.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - Validation Loss: 0.0397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 5: 100%|██████████| 871/871 [00:12<00:00, 70.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - Validation Loss: 0.0390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 6: 100%|██████████| 871/871 [00:16<00:00, 51.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - Validation Loss: 0.0391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 7: 100%|██████████| 871/871 [00:11<00:00, 73.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - Validation Loss: 0.0406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 8: 100%|██████████| 871/871 [00:11<00:00, 76.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - Validation Loss: 0.0403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 9: 100%|██████████| 871/871 [00:13<00:00, 63.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - Validation Loss: 0.0417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 10: 100%|██████████| 871/871 [00:12<00:00, 70.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - Validation Loss: 0.0427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 11: 100%|██████████| 871/871 [00:12<00:00, 71.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 - Validation Loss: 0.0432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 12: 100%|██████████| 871/871 [00:12<00:00, 69.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - Validation Loss: 0.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 13: 100%|██████████| 871/871 [00:13<00:00, 66.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - Validation Loss: 0.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 14: 100%|██████████| 871/871 [00:12<00:00, 70.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 - Validation Loss: 0.0444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retraining Epoch 15: 100%|██████████| 871/871 [00:12<00:00, 70.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - Validation Loss: 0.0453\n"
     ]
    }
   ],
   "source": [
    "set_seeds(51)\n",
    "# Load the best model to start fine-tuning\n",
    "retrain_model = ModernLeNet5().to(device)\n",
    "retrain_model.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "\n",
    "# Use a smaller learning rate for fine-tuning\n",
    "retrain_optimizer = Adam(retrain_model.parameters(), lr=0.0001)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Reload the validation loader\n",
    "val_dataset = fo.load_dataset(\"mnist-validation-set\")\n",
    "torch_val_set = CustomTorchImageDataset(val_dataset, image_transforms, label_map)\n",
    "val_loader = torch.utils.data.DataLoader(torch_val_set, batch_size=64)\n",
    "\n",
    "# Training loop\n",
    "retrain_epochs = 15\n",
    "best_retrain_val_loss = float('inf')\n",
    "retrain_model_save_path = Path(os.getcwd()) / 'retrained_lenet.pth'\n",
    "\n",
    "for epoch in range(retrain_epochs):\n",
    "    retrain_model.train()\n",
    "    # Simplified training and validation epoch functions for brevity\n",
    "    for images, labels in tqdm(combined_train_loader, desc=f\"Retraining Epoch {epoch+1}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        retrain_optimizer.zero_grad()\n",
    "        logits = retrain_model(images)\n",
    "        loss = ce_loss(logits, labels)\n",
    "        loss.backward()\n",
    "        retrain_optimizer.step()\n",
    "\n",
    "    retrain_model.eval()\n",
    "    val_losses = []\n",
    "    with torch.inference_mode():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = retrain_model(images)\n",
    "            val_losses.append(ce_loss(logits, labels).item())\n",
    "    \n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    print(f\"Epoch {epoch+1} - Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    if avg_val_loss < best_retrain_val_loss:\n",
    "        best_retrain_val_loss = avg_val_loss\n",
    "        torch.save(retrain_model.state_dict(), retrain_model_save_path)\n",
    "        print(\"Saved improved retrained model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation\n",
    "\n",
    "Finally, let's evaluate our newly fine-tuned model on the test set and compare its performance to the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrained model:   3%|▎         | 4/157 [00:00<00:04, 38.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating retrained model: 100%|██████████| 157/157 [00:03<00:00, 47.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrained predictions stored.\n"
     ]
    }
   ],
   "source": [
    "# Load the best retrained model\n",
    "final_model = ModernLeNet5().to(device)\n",
    "final_model.load_state_dict(torch.load(retrain_model_save_path, map_location=device))\n",
    "final_model.eval()\n",
    "\n",
    "# Create test loader\n",
    "torch_test_set = CustomTorchImageDataset(test_dataset, image_transforms, label_map)\n",
    "test_loader = torch.utils.data.DataLoader(torch_test_set, batch_size=64)\n",
    "\n",
    "# Run inference with the retrained model\n",
    "retrained_predictions, retrained_logits = [], []\n",
    "with torch.inference_mode():\n",
    "    for images, _ in tqdm(test_loader, desc=\"Evaluating retrained model\"):\n",
    "        logits = final_model(images.to(device))\n",
    "        retrained_logits.append(logits.cpu().numpy())\n",
    "        retrained_predictions.extend(torch.max(logits.data, 1)[1].cpu().numpy())\n",
    "\n",
    "retrained_logits = np.concatenate(retrained_logits, axis=0)\n",
    "\n",
    "# Store retrained predictions in FiftyOne\n",
    "for i, sample in enumerate(test_dataset):\n",
    "    pred_idx = retrained_predictions[i]\n",
    "    logits = retrained_logits[i]\n",
    "    conf = float(Fun.softmax(torch.tensor(logits), dim=0)[pred_idx])\n",
    "    sample[\"retrained_lenet_classification\"] = fo.Classification(\n",
    "        label=dataset_classes[pred_idx], confidence=conf, logits=logits.tolist()\n",
    "    )\n",
    "    sample.save()\n",
    "\n",
    "print(\"Retrained predictions stored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Original Model Performance ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    0 - zero       1.00      0.99      0.99       980\n",
      "     1 - one       1.00      0.99      0.99      1135\n",
      "     2 - two       0.99      0.99      0.99      1032\n",
      "   3 - three       0.99      0.99      0.99      1010\n",
      "    4 - four       0.98      0.99      0.99       982\n",
      "    5 - five       0.98      0.99      0.98       892\n",
      "     6 - six       1.00      0.99      0.99       958\n",
      "   7 - seven       0.98      0.99      0.99      1028\n",
      "   8 - eight       0.99      0.99      0.99       974\n",
      "    9 - nine       0.99      0.98      0.98      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "\n",
      "--- Retrained Model Performance ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    0 - zero       0.99      1.00      1.00       980\n",
      "     1 - one       0.99      0.99      0.99      1135\n",
      "     2 - two       1.00      0.99      0.99      1032\n",
      "   3 - three       0.99      1.00      0.99      1010\n",
      "    4 - four       0.99      0.99      0.99       982\n",
      "    5 - five       0.99      0.99      0.99       892\n",
      "     6 - six       0.99      0.99      0.99       958\n",
      "   7 - seven       0.99      0.99      0.99      1028\n",
      "   8 - eight       0.99      0.99      0.99       974\n",
      "    9 - nine       0.99      0.99      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "\n",
      "Accuracy Improvement: +0.0020\n"
     ]
    }
   ],
   "source": [
    "# Evaluate original and retrained models\n",
    "original_eval = test_dataset.evaluate_classifications(\"lenet_classification\", eval_key=\"original_eval\")\n",
    "retrained_eval = test_dataset.evaluate_classifications(\"retrained_lenet_classification\", eval_key=\"retrained_eval\")\n",
    "\n",
    "print(\"\\n--- Original Model Performance ---\")\n",
    "original_eval.print_report()\n",
    "\n",
    "print(\"\\n--- Retrained Model Performance ---\")\n",
    "retrained_eval.print_report()\n",
    "\n",
    "# Compare performance\n",
    "orig_accuracy = original_eval.metrics()['accuracy']\n",
    "retrain_accuracy = retrained_eval.metrics()['accuracy']\n",
    "print(f\"\\nAccuracy Improvement: {retrain_accuracy - orig_accuracy:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Changes\n",
    "\n",
    "Let's see exactly which samples were fixed by retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "originally_wrong = test_dataset.match(F(\"lenet_classification.label\") != F(\"ground_truth.label\"))\n",
    "\n",
    "now_correct = originally_wrong.match(F(\"retrained_lenet_classification.label\") == F(\"ground_truth.label\"))\n",
    "\n",
    "now_wrong = test_dataset.match(\n",
    "    (F(\"lenet_classification.label\") == F(\"ground_truth.label\")) & \n",
    "    (F(\"retrained_lenet_classification.label\") != F(\"ground_truth.label\"))\n",
    ")\n",
    "\n",
    "# Save these views in the test_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Samples fixed by retraining: {len(now_correct)}\")\n",
    "print(f\"Samples broken by retraining: {len(now_wrong)}\")\n",
    "print(f\"Net improvement in correct predictions: {len(now_correct) - len(now_wrong)}\")\n",
    "\n",
    "session = fo.launch_app(test_dataset, auto=False)\n",
    "session.view = now_correct\n",
    "print(f\"\\nView the fixed samples in the App: {session.url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the curated MNIST sets to your hard drive\n",
    "\n",
    "Time to save our work! Local copies protect against data loss and enable easy dataset distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mnist-test-set',\n",
       " 'mnist-train-val',\n",
       " 'mnist-training-set',\n",
       " 'mnist-validation-set']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We list the datasets that we have available on this session.\n",
    "fo.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/root/fiftyone/docs/source/getting_started_experiences/Classification/Classification/mnist_datasets/train' already exists; export will be merged with existing files\n",
      " 100% |█████████████| 51000/51000 [38.5s elapsed, 0s remaining, 1.3K samples/s]       \n",
      "Directory '/root/fiftyone/docs/source/getting_started_experiences/Classification/Classification/mnist_datasets/validation' already exists; export will be merged with existing files\n",
      " 100% |███████████████| 9000/9000 [4.6s elapsed, 0s remaining, 2.1K samples/s]        \n",
      "Directory '/root/fiftyone/docs/source/getting_started_experiences/Classification/Classification/mnist_datasets/test' already exists; export will be merged with existing files\n",
      " 100% |█████████████| 10000/10000 [11.8s elapsed, 0s remaining, 840.5 samples/s]      \n",
      "Datasets exported to: /root/fiftyone/docs/source/getting_started_experiences/Classification/Classification/mnist_datasets\n",
      "Train: 51000 samples\n",
      "Validation: 9000 samples\n",
      "Test: 10000 samples\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create the directory structure using pathlib\n",
    "base_dir = Path.cwd() / \"Classification\"\n",
    "export_dir = base_dir / \"mnist_datasets\"\n",
    "\n",
    "# Create directories for each split\n",
    "train_dir = export_dir / \"train\"\n",
    "val_dir = export_dir / \"validation\"\n",
    "test_dir = export_dir / \"test\"\n",
    "\n",
    "train_dir.mkdir(parents=True, exist_ok=True)\n",
    "val_dir.mkdir(parents=True, exist_ok=True)\n",
    "test_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load and export each dataset\n",
    "# Training set\n",
    "train_dataset = fo.load_dataset(\"mnist-training-set\")\n",
    "train_dataset.export(\n",
    "    export_dir=str(train_dir),\n",
    "    dataset_type=fo.types.ImageClassificationDirectoryTree,\n",
    "    label_field=\"ground_truth\"\n",
    ")\n",
    "\n",
    "# Validation set\n",
    "val_dataset = fo.load_dataset(\"mnist-validation-set\")\n",
    "val_dataset.export(\n",
    "    export_dir=str(val_dir),\n",
    "    dataset_type=fo.types.ImageClassificationDirectoryTree,\n",
    "    label_field=\"ground_truth\"\n",
    ")\n",
    "\n",
    "# Test set\n",
    "test_dataset = fo.load_dataset(\"mnist-test-set\")\n",
    "test_dataset.export(\n",
    "    export_dir=str(test_dir),\n",
    "    dataset_type=fo.types.ImageClassificationDirectoryTree,\n",
    "    label_field=\"ground_truth\"\n",
    ")\n",
    "\n",
    "print(f\"Datasets exported to: {export_dir}\")\n",
    "print(f\"Train: {len(train_dataset)} samples\")\n",
    "print(f\"Validation: {len(val_dataset)} samples\")\n",
    "print(f\"Test: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the curated MNIST datasets to your HuggingFace account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "1. Apply and visualize different augmentations to the training dataset. Try using the [community plug-in](https://github.com/jacobmarks/fiftyone-albumentations-plugin) to do this within the FiftyOne app. \n",
    "2. Try retraining and evaluating the LeNet model after removing the most quirky images from the train, validation, and testing sets. Report how this is affecting the overall accuracy of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have completed the entire workflow from data exploration to model training, analysis, and targeted improvement. You've seen how a generalist model like CLIP provides a baseline, and how a specialized, supervised model can achieve superior performance. Most importantly, you've learned how to use model predictions and embeddings to analyze your dataset, find problematic samples, and use that information to make your model even better.\n",
    "\n",
    "Please see `summary.md` for a full recap and suggested next steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
